1
00:00:05,270 --> 00:00:08,520
All right. Hi everyone. Okay, I guess we're live.

2
00:00:08,520 --> 00:00:12,030
Ah, so as- as- Aarti was saying,

3
00:00:12,030 --> 00:00:13,395
please enter your SUNetID.

4
00:00:13,395 --> 00:00:18,210
Ah, we can bring this up again at the end of class today.

5
00:00:18,210 --> 00:00:20,760
We'll just take another like, what 20 seconds?

6
00:00:20,760 --> 00:00:23,160
And then we'll- we'll go on to the main discussion.

7
00:00:23,160 --> 00:00:25,240
[NOISE] All right.

8
00:00:33,890 --> 00:00:39,440
So, um, what I want to discuss with you today is,

9
00:00:39,440 --> 00:00:44,810
um, ah, what I'm going to call full cycle deep learning applications, right?

10
00:00:44,810 --> 00:00:54,435
Um, [NOISE] and so,

11
00:00:54,435 --> 00:00:56,785
um, I think this Sunday, uh,

12
00:00:56,785 --> 00:00:59,870
you'll be submitting your proposals for the,

13
00:00:59,870 --> 00:01:02,435
ah, class projects you do this quarter.

14
00:01:02,435 --> 00:01:05,970
And, um, in most of the, uh,

15
00:01:05,970 --> 00:01:08,390
in- in a lot of what you learn about the machine learning projects,

16
00:01:08,390 --> 00:01:10,715
you learn how to build machine learning models.

17
00:01:10,715 --> 00:01:13,220
Um, what I want to do today is share with you

18
00:01:13,220 --> 00:01:17,315
the bigger context of how a machine learning model,

19
00:01:17,315 --> 00:01:20,130
you know, how a neural network you might train, uh,

20
00:01:20,130 --> 00:01:23,255
fits in the context of a bigger project.

21
00:01:23,255 --> 00:01:24,740
Uh, so what are all the steps, right?

22
00:01:24,740 --> 00:01:27,305
Just as if you're writing a software product,

23
00:01:27,305 --> 00:01:28,580
you know, you take another classes,

24
00:01:28,580 --> 00:01:30,260
then you, uh, what happened?

25
00:01:30,260 --> 00:01:33,910
That, uh, they teach you how to build a website for example.

26
00:01:33,910 --> 00:01:38,035
What is that? Um, but

27
00:01:38,035 --> 00:01:41,750
to build a product requires more than just building a website, right?

28
00:01:41,750 --> 00:01:43,850
So, what are the- what are the other things you need to do to

29
00:01:43,850 --> 00:01:46,070
actually do a successful software project?

30
00:01:46,070 --> 00:01:50,005
And in this case, to do a successful machine learning application.

31
00:01:50,005 --> 00:01:54,170
Um, and so, uh,

32
00:01:54,170 --> 00:01:58,080
let's see. So- so, yeah.

33
00:01:58,250 --> 00:02:00,900
Test, test, is the audio on?

34
00:02:00,900 --> 00:02:03,240
Test. Could you turn up the audio?

35
00:02:03,240 --> 00:02:04,890
Yeah, how is this?

36
00:02:04,890 --> 00:02:06,210
No? Can't here me now.

37
00:02:06,210 --> 00:02:07,260
Hey.

38
00:02:07,260 --> 00:02:09,365
Oh, I think I'm broadcasting.

39
00:02:09,365 --> 00:02:10,820
I hear myself great.

40
00:02:10,820 --> 00:02:14,540
[LAUGHTER] Okay, you can hear me now.

41
00:02:14,540 --> 00:02:17,630
Great. Thank you. All right. Thank you. All right.

42
00:02:17,630 --> 00:02:19,520
So, what I want to do is share with you,

43
00:02:19,520 --> 00:02:20,995
um, full cycle machine learning.

44
00:02:20,995 --> 00:02:22,480
Not just how to, uh,

45
00:02:22,480 --> 00:02:25,550
you learn a lot about how to build deep learning models

46
00:02:25,550 --> 00:02:28,400
but how does that fit in a bigger project, right?

47
00:02:28,400 --> 00:02:30,635
Just as if you're taking the class on building a website,

48
00:02:30,635 --> 00:02:33,695
you know, then great, you know how the code of a website, that's really valuable.

49
00:02:33,695 --> 00:02:36,710
But what are all the things you need to do to make a successful website?

50
00:02:36,710 --> 00:02:38,150
Or to build a- build a project that

51
00:02:38,150 --> 00:02:40,745
involves launching a website or mobile app or whatever.

52
00:02:40,745 --> 00:02:45,090
Um, so as- as you plan for your,

53
00:02:45,090 --> 00:02:47,595
um, class project proposals, uh,

54
00:02:47,595 --> 00:02:49,260
due this Sunday, uh,

55
00:02:49,260 --> 00:02:54,320
if you're doing an application project that fits in the context of a bigger application,

56
00:02:54,320 --> 00:02:57,300
um, also keep all these steps in mind, right?

57
00:02:57,300 --> 00:02:59,350
So, um, you know,

58
00:02:59,350 --> 00:03:04,505
these are what I think of as the steps of an ML project,

59
00:03:04,505 --> 00:03:07,230
or really maybe- maybe not fast project but

60
00:03:07,230 --> 00:03:11,910
maybe a serious machine learning application, right?

61
00:03:11,910 --> 00:03:16,460
And I think, oh, no I built a lot of machine learning products over several years.

62
00:03:16,460 --> 00:03:19,070
So, some of these are also things that I wish I had known,

63
00:03:19,070 --> 00:03:20,555
you know, many years ago.

64
00:03:20,555 --> 00:03:28,170
Um, one, does this kind of- maybe kind of obvious but,

65
00:03:28,170 --> 00:03:30,685
you know, select a problem.

66
00:03:30,685 --> 00:03:35,055
And let's say for the sake of simplicity data,

67
00:03:35,055 --> 00:03:37,350
you use supervised learning, right.

68
00:03:37,350 --> 00:03:40,530
It- it turns out for the CS 230 class projects I think,

69
00:03:40,530 --> 00:03:44,070
uh, more than 50 percent of the class projects tend to use supervised learning.

70
00:03:44,070 --> 00:03:46,590
There are also other projects that use- end up

71
00:03:46,590 --> 00:03:49,390
using GANs which we'll talk about later this quarter or other things.

72
00:03:49,390 --> 00:03:50,515
But I think, you know,

73
00:03:50,515 --> 00:03:54,130
let's say you use supervised learning to- to build interesting application.

74
00:03:54,130 --> 00:03:57,425
Um, and- and I think for today,

75
00:03:57,425 --> 00:04:01,705
I'm going to use as a running example of building a,

76
00:04:01,705 --> 00:04:04,940
um, building a- a voice-activated device, right?

77
00:04:04,940 --> 00:04:07,105
So, you know, uh, no, actually,

78
00:04:07,105 --> 00:04:09,920
how- how many of you have like a smart speaker in your home?

79
00:04:09,920 --> 00:04:12,340
Like a voice-activated device in your home?

80
00:04:12,340 --> 00:04:14,175
You know, the- in- in the US?

81
00:04:14,175 --> 00:04:16,555
Well, not that many of you, interesting. Okay cool.

82
00:04:16,555 --> 00:04:20,540
Yeah, so, I think, uh, you know the- the Amazon Echos, Google Homes,

83
00:04:20,540 --> 00:04:23,525
the Apple Siris or the- the- in- in China,

84
00:04:23,525 --> 00:04:26,510
my- one of former team's built Baidu DeurOS.

85
00:04:26,510 --> 00:04:30,170
Ah, ah but let's say for the sake of

86
00:04:30,170 --> 00:04:33,550
argument that you want to build a voice-activated device.

87
00:04:33,550 --> 00:04:35,615
And I'm going to use as a running example.

88
00:04:35,615 --> 00:04:39,580
Um, and so in order to build a voice-activated device,

89
00:04:39,580 --> 00:04:41,390
and- and again I'm not going to use any of

90
00:04:41,390 --> 00:04:44,630
the commercial brands like Alexa or OK Google or Hey Siri

91
00:04:44,630 --> 00:04:50,420
or I guess in China it was a Hello [FOREIGN] which means kind of roughly hello little du.

92
00:04:50,420 --> 00:04:53,690
Um, but let's use a more neutral word which as I see you

93
00:04:53,690 --> 00:04:56,975
wanted to build a device that your responsive word activate.

94
00:04:56,975 --> 00:05:01,100
Um, and you're actually going to implement this as a problem set later this quarter.

95
00:05:01,100 --> 00:05:05,160
Um, but so you want to build a yeah.

96
00:05:05,970 --> 00:05:07,390
Is it possible to [inaudible].

97
00:05:07,390 --> 00:05:09,710
Okay. No. Volume up.

98
00:05:09,710 --> 00:05:14,780
Uh, uh, let's see how that- okay is this better?

99
00:05:14,780 --> 00:05:17,265
No? Yes? No? This is better?

100
00:05:17,265 --> 00:05:18,990
Okay, cool. Thank you. Look at how ironic,

101
00:05:18,990 --> 00:05:22,020
talk about speech recognition and the volume isn't high enough.

102
00:05:22,020 --> 00:05:25,440
Okay. um, so let's say you want- well,

103
00:05:25,440 --> 00:05:28,640
[LAUGHTER] let me know about comes off again and thank you.

104
00:05:28,640 --> 00:05:31,730
Okay. Um, so let's say you want to build a voice-activated device.

105
00:05:31,730 --> 00:05:33,529
So, the key components,

106
00:05:33,529 --> 00:05:34,550
the key machine learning,

107
00:05:34,550 --> 00:05:38,300
deep learning component is going to be a learning algorithm

108
00:05:38,300 --> 00:05:43,260
that takes as input an audio clip and,

109
00:05:43,260 --> 00:05:51,930
uh, outputs, um, did it detect what's sometimes called the trigger word.

110
00:05:53,420 --> 00:05:56,595
Did I go soft again? Okay, this is okay, great.

111
00:05:56,595 --> 00:05:58,575
All right and- and O plus Y,

112
00:05:58,575 --> 00:05:59,895
you know zero one,

113
00:05:59,895 --> 00:06:02,970
they did detect their trigger word such as Alexa,

114
00:06:02,970 --> 00:06:04,740
or OK Google or Hey Siri,

115
00:06:04,740 --> 00:06:07,600
or Hello [inaudible] or, um,

116
00:06:07,600 --> 00:06:11,685
or activate or whatever wake word or trigger word, right?

117
00:06:11,685 --> 00:06:18,360
Um, and so step one is,

118
00:06:18,360 --> 00:06:20,685
uh, select a problem.

119
00:06:20,685 --> 00:06:25,030
Um, and then, in order to train a learning algorithm,

120
00:06:25,030 --> 00:06:29,910
you need to get labeled data if you're applying supervised learning.

121
00:06:31,390 --> 00:06:36,640
And then you design a model,

122
00:06:38,630 --> 00:06:43,144
use back prop or some of the other algorithms you learned about momentum,

123
00:06:43,144 --> 00:06:46,595
Adam, so you know, this optimization algorithms gradient descend,

124
00:06:46,595 --> 00:06:48,385
to train the model.

125
00:06:48,385 --> 00:06:53,770
Um, and then maybe you test it on your test set.

126
00:06:55,870 --> 00:07:00,710
And then you deploy it meaning you start selling these smart speakers and,

127
00:07:00,710 --> 00:07:04,205
you know, putting them into hopefully into your users homes.

128
00:07:04,205 --> 00:07:11,955
Um, and then you have to maintain the system.

129
00:07:11,955 --> 00:07:13,610
I'll talk about this later as well.

130
00:07:13,610 --> 00:07:16,850
Uh, and- and this is not chronological but, ah,

131
00:07:16,850 --> 00:07:18,320
one thing that's often done,

132
00:07:18,320 --> 00:07:21,845
but I- I want to talk about it at the end instead is not really step eight.

133
00:07:21,845 --> 00:07:23,930
It's a QA which is, uh,

134
00:07:23,930 --> 00:07:26,630
quality assurance which is an ongoing process, right?

135
00:07:26,630 --> 00:07:31,305
And so, um, one, uh, let's see.

136
00:07:31,305 --> 00:07:33,645
So, as you- so if you want to build a product,

137
00:07:33,645 --> 00:07:35,170
if you want to sell a machine learning product,

138
00:07:35,170 --> 00:07:38,825
these are maybe some of the key steps you need to work on.

139
00:07:38,825 --> 00:07:42,495
Um, some observations, when you train a model,

140
00:07:42,495 --> 00:07:45,060
training a model is often a very iterative process.

141
00:07:45,060 --> 00:07:46,875
So, every time we train the machine learning model,

142
00:07:46,875 --> 00:07:48,505
you'll find that, you know,

143
00:07:48,505 --> 00:07:51,320
I can almost guarantee whatever you do,

144
00:07:51,320 --> 00:07:52,460
it will not work.

145
00:07:52,460 --> 00:07:54,350
At least not the first time, right?

146
00:07:54,350 --> 00:07:57,665
And so you'll find that even though I've written these, uh, sequence of steps,

147
00:07:57,665 --> 00:07:59,300
when you train a model, you undergo,

148
00:07:59,300 --> 00:08:02,270
no- that neural network architecture didn't work.

149
00:08:02,270 --> 00:08:05,630
and need to increase the number of hidden units or change the regularization

150
00:08:05,630 --> 00:08:09,410
or switch to RNN or switch to a totally different architecture.

151
00:08:09,410 --> 00:08:13,000
And sometimes you train a model and go nope, that didn't work.

152
00:08:13,000 --> 00:08:15,720
Um, I need to get more data, right?

153
00:08:15,720 --> 00:08:20,420
And so this is often a very iterative process we are cycling through,

154
00:08:20,420 --> 00:08:23,400
um, uh, the several different steps here.

155
00:08:23,400 --> 00:08:25,335
Um, and then I think, ah,

156
00:08:25,335 --> 00:08:28,880
one distinction that you have not yet learned about in the Coursera- in

157
00:08:28,880 --> 00:08:31,370
the deeplearning.ai Coursera videos is how to

158
00:08:31,370 --> 00:08:34,010
split up the data into train, dev, and tests.

159
00:08:34,010 --> 00:08:36,515
So, I am going to simplify those details for now.

160
00:08:36,515 --> 00:08:40,809
But just as a- a foreshadowing I guess of what,

161
00:08:40,809 --> 00:08:43,704
um, you learn later in the- in the, uh,

162
00:08:43,705 --> 00:08:46,880
deeplearning.ai Coursera videos is how to take a data set,

163
00:08:46,880 --> 00:08:48,725
you have trained into- excuse me,

164
00:08:48,725 --> 00:08:50,840
into a training set, um,

165
00:08:50,840 --> 00:08:54,800
ah, into a set that you actually test cross-validate

166
00:08:54,800 --> 00:08:57,940
using during development called the dev set or development set

167
00:08:57,940 --> 00:08:59,260
or [inaudible] cross validation set.

168
00:08:59,260 --> 00:09:00,350
That was a separate test set.

169
00:09:00,350 --> 00:09:01,730
So, you'll learn about this later.

170
00:09:01,730 --> 00:09:05,150
But I'm just simplifying a little bit, um, for today.

171
00:09:05,150 --> 00:09:11,285
Okay. So, um, so I think,

172
00:09:11,285 --> 00:09:17,130
um, the first thing I want to do is ask you a question, right?

173
00:09:17,130 --> 00:09:18,770
So, we're going to talk through many of these steps.

174
00:09:18,770 --> 00:09:20,540
And when it turns out that, um,

175
00:09:20,540 --> 00:09:24,155
what a lot of machine learning classes do and- and do a good job teaching

176
00:09:24,155 --> 00:09:28,200
is focusing on maybe these three steps,

177
00:09:28,200 --> 00:09:30,410
or maybe these four steps, right?

178
00:09:30,410 --> 00:09:33,050
And what I want to do today is spend more time,

179
00:09:33,050 --> 00:09:35,195
so this is the heart of machine learning,

180
00:09:35,195 --> 00:09:37,100
how do you build a great model.

181
00:09:37,100 --> 00:09:40,895
Uh, and what I want to do today is spend more time talking about step one,

182
00:09:40,895 --> 00:09:42,590
uh, and six and seven,

183
00:09:42,590 --> 00:09:44,420
and then just a little bit of time talking about

184
00:09:44,420 --> 00:09:46,340
the core of this because you kind of need to do

185
00:09:46,340 --> 00:09:47,560
the other steps as well when you want build

186
00:09:47,560 --> 00:09:50,555
a deep learning product or build a machine learning application.

187
00:09:50,555 --> 00:09:54,455
Okay. Um, so let's talk about discussion question.

188
00:09:54,455 --> 00:09:57,900
Um, I'm actually curious.

189
00:09:57,900 --> 00:10:02,220
Uh, if you're selecting a, um,

190
00:10:02,220 --> 00:10:04,950
project to work on, uh,

191
00:10:04,950 --> 00:10:09,105
uh, what are the- actually so I- don't- don't answer this yet.

192
00:10:09,105 --> 00:10:11,340
I'll- I'll tell you what the question I'm going to ask is,

193
00:10:11,340 --> 00:10:16,220
um, which is- [NOISE]

194
00:10:16,220 --> 00:10:20,515
All right. Uh, what properties make for a good candidate deep learning project?

195
00:10:20,515 --> 00:10:21,775
But don't answer yet, right?

196
00:10:21,775 --> 00:10:23,650
So I, I wanna say a few more things before,

197
00:10:23,650 --> 00:10:25,195
before I invite you to answer,

198
00:10:25,195 --> 00:10:26,410
which is that, um,

199
00:10:26,410 --> 00:10:27,820
all of you, for the last few days,

200
00:10:27,820 --> 00:10:30,505
I hope, have been thinking about what project you wanna do for this class.

201
00:10:30,505 --> 00:10:33,820
And what I wanna do is just discuss some properties of what are

202
00:10:33,820 --> 00:10:37,620
good projects to work on and what are maybe not good projects to work on, okay?

203
00:10:37,620 --> 00:10:41,535
And, and think of this as your chance to give your classmates advice, right?

204
00:10:41,535 --> 00:10:43,470
What are the things your classmates should think about if they can't

205
00:10:43,470 --> 00:10:45,870
decide this is a good project to work on, okay?

206
00:10:45,870 --> 00:10:49,750
Um, and so, what I wanna do for today is, ah,

207
00:10:49,750 --> 00:10:53,755
use, um, this voice-activated thing as a mo- as a,

208
00:10:53,755 --> 00:10:55,105
as a motivating example.

209
00:10:55,105 --> 00:10:57,790
And, you know, th- there's actually one project I, uh,

210
00:10:57,790 --> 00:11:00,205
uh, was working on,

211
00:11:00,205 --> 00:11:01,720
uh, the, the, actually,

212
00:11:01,720 --> 00:11:03,430
I thought, there were, actually, there's one project I thought of

213
00:11:03,430 --> 00:11:05,830
working on but decided not to work on,

214
00:11:05,830 --> 00:11:08,455
ah, and that, that, that's a voice-activated device.

215
00:11:08,455 --> 00:11:10,570
So, it turns out that [NOISE] , um,

216
00:11:10,570 --> 00:11:13,810
these voice-activated devices like Echo, Google Homes, and so on,

217
00:11:13,810 --> 00:11:17,305
they are taking off quite rapidly in the US and around the world.

218
00:11:17,305 --> 00:11:19,900
Um, it turns out that one of the, you know,

219
00:11:19,900 --> 00:11:23,005
significant pain points of these devices is the need to,

220
00:11:23,005 --> 00:11:24,730
um, configure it, right?

221
00:11:24,730 --> 00:11:26,410
To set it up for Wi-Fi.

222
00:11:26,410 --> 00:11:29,845
So, um, I've done a lot of work on speech recognition, you know, ah,

223
00:11:29,845 --> 00:11:32,410
a hotel, did a lot of work on group speech system,

224
00:11:32,410 --> 00:11:33,850
I led the Baidu speech system.

225
00:11:33,850 --> 00:11:36,130
So I've been published papers on speech recognition,

226
00:11:36,130 --> 00:11:39,775
and I have a, I have one of these devices in my home, right?

227
00:11:39,775 --> 00:11:42,625
Um, well, a- actually, Amazon, I have an Amazon Echo in my living room.

228
00:11:42,625 --> 00:11:44,935
Um, but even to this day,

229
00:11:44,935 --> 00:11:48,490
I have configured exactly one light bulb to be hooked up,

230
00:11:48,490 --> 00:11:50,020
to be controlled by my Echo,

231
00:11:50,020 --> 00:11:52,075
[LAUGHTER] because the, the seller process,

232
00:11:52,075 --> 00:11:53,245
not blaming any country,

233
00:11:53,245 --> 00:11:55,315
it's just difficult to hook up, you know,

234
00:11:55,315 --> 00:11:58,405
a Wi-Fi enabled light bulb and then to

235
00:11:58,405 --> 00:12:01,600
set it up so that your s- smart speaker or whatever,

236
00:12:01,600 --> 00:12:04,480
as in, say, you know, "Smart device, turn off the lamp."

237
00:12:04,480 --> 00:12:07,570
So, I, I have one light bulb in my living room where,

238
00:12:07,570 --> 00:12:09,910
that I can [LAUGHTER] turn on and off and that's it, right?

239
00:12:09,910 --> 00:12:12,325
[LAUGHTER] Ah, even as a speech researcher.

240
00:12:12,325 --> 00:12:17,830
So, [LAUGHTER] um, maybe that's even a bad example.

241
00:12:17,830 --> 00:12:19,705
Um, so one, one,

242
00:12:19,705 --> 00:12:21,730
one application that I think, ah,

243
00:12:21,730 --> 00:12:25,780
that the, I, I was actually searching because you're working on is to build a, um,

244
00:12:25,780 --> 00:12:29,754
embedded device that you can sell to lamp makers,

245
00:12:29,754 --> 00:12:32,290
so that, I don't know where you buy your lamps from, but, you know,

246
00:12:32,290 --> 00:12:33,700
I have a few lamps from IKEA,

247
00:12:33,700 --> 00:12:35,065
or a few lamps from wherever.

248
00:12:35,065 --> 00:12:36,610
But you can buy a desk lamp,

249
00:12:36,610 --> 00:12:39,265
[NOISE] so that when you buy the desk lamp,

250
00:12:39,265 --> 00:12:41,875
there's already a built-in microphone,

251
00:12:41,875 --> 00:12:45,505
so that without needing to connect this thing to Wi-Fi, you know, and say,

252
00:12:45,505 --> 00:12:48,100
"Hey here's a $20 desk lamp, um,

253
00:12:48,100 --> 00:12:50,635
put them on your desk," and you can go home and say,

254
00:12:50,635 --> 00:12:51,685
"Desk lamp, turn on,

255
00:12:51,685 --> 00:12:53,170
or desk lamp, turn off."

256
00:12:53,170 --> 00:12:56,215
Uh, then, I think that will help a lot more

257
00:12:56,215 --> 00:12:59,575
users get voice-activated devices into their home.

258
00:12:59,575 --> 00:13:01,075
And it's actually not clear to me,

259
00:13:01,075 --> 00:13:03,055
if you want to turn on a desk lamp,

260
00:13:03,055 --> 00:13:06,760
it's actually not clear to me that you want to turn to a smart speaker and say,

261
00:13:06,760 --> 00:13:10,210
"Hey, Smart Speaker, please turn on that lamp over there," right?

262
00:13:10,210 --> 00:13:12,550
I- it, it, maybe it feels more natural to just talk

263
00:13:12,550 --> 00:13:15,340
directly to a desk lamp and tell it to turn on and turn off.

264
00:13:15,340 --> 00:13:18,910
Um, and so, ah, a- also for what it's worth,

265
00:13:18,910 --> 00:13:20,710
someone we're friends now with evaluated this,

266
00:13:20,710 --> 00:13:23,440
we actually thought that this could be a r- reasonable business,

267
00:13:23,440 --> 00:13:24,835
to build embedded devices,

268
00:13:24,835 --> 00:13:28,930
to sell to lamp makers or other device makers so that they can sell

269
00:13:28,930 --> 00:13:33,520
their own voice-activated devices without needing this complicated Wi-Fi setup process.

270
00:13:33,520 --> 00:13:35,620
Um, and so to do this,

271
00:13:35,620 --> 00:13:37,315
you would need to build a learning algorithm,

272
00:13:37,315 --> 00:13:39,040
and have it run on an embedded device,

273
00:13:39,040 --> 00:13:41,905
then it just inputs an audio clip and outputs,

274
00:13:41,905 --> 00:13:44,620
you know, whenever it detects the, the, the wake word.

275
00:13:44,620 --> 00:13:48,520
And instead of a wake word being "Activate," the wake word would be a "Lamp,

276
00:13:48,520 --> 00:13:50,050
turn on" or "Lamp, turn off."

277
00:13:50,050 --> 00:13:51,790
You need two wake words or trigger words,

278
00:13:51,790 --> 00:13:54,730
one to turn it on, one to turn it off, right?

279
00:13:54,730 --> 00:13:57,160
Oh, and, and, and, and I think just the other thing that,

280
00:13:57,160 --> 00:13:59,095
um, I think would make this work,

281
00:13:59,095 --> 00:14:01,390
ah, is, um, ah, ah, to, ah,

282
00:14:01,390 --> 00:14:03,775
to give these devices names.

283
00:14:03,775 --> 00:14:06,160
So, if you have five lamps, or two lamps, you,

284
00:14:06,160 --> 00:14:08,950
you need an wait index into these different desk lamps.

285
00:14:08,950 --> 00:14:11,815
So, um, let's say you decide for your project,

286
00:14:11,815 --> 00:14:13,630
you know, to have a little switch here,

287
00:14:13,630 --> 00:14:15,610
so this lamp could be called John,

288
00:14:15,610 --> 00:14:18,520
[NOISE] or Mary, or Bob,

289
00:14:18,520 --> 00:14:20,740
or Alice, like a four-way switch.

290
00:14:20,740 --> 00:14:24,130
So that's depending on where you set this four-way switch, you can say,

291
00:14:24,130 --> 00:14:25,840
you know, "John," right?

292
00:14:25,840 --> 00:14:27,655
"Turn on," right?

293
00:14:27,655 --> 00:14:29,860
O- or d- if, if you decide to call this lamp John,

294
00:14:29,860 --> 00:14:31,540
I guess you could give some other names so you don't have

295
00:14:31,540 --> 00:14:33,775
any lamp by the same name, okay?

296
00:14:33,775 --> 00:14:37,510
Um, so, what I'm gonna do is use as a, ah,

297
00:14:37,510 --> 00:14:41,785
motivating example on this as a possible project.

298
00:14:41,785 --> 00:14:43,375
Oh, and, and I'm not working on this.

299
00:14:43,375 --> 00:14:45,250
If any of you want to build a startup doing this,

300
00:14:45,250 --> 00:14:47,995
go for it, I, I, this is not net, [NOISE] well,

301
00:14:47,995 --> 00:14:49,960
I, I felt my teams and I, we had better ideas,

302
00:14:49,960 --> 00:14:51,220
so we wanted to do other things in this

303
00:14:51,220 --> 00:14:52,795
but I actually don't see anything wrong with this.

304
00:14:52,795 --> 00:14:54,730
I think this actually could be a reasonable thing

305
00:14:54,730 --> 00:14:56,290
to pursue as well, but I'm not doing it.

306
00:14:56,290 --> 00:14:58,090
So you're all very welcome to, if you want, okay?

307
00:14:58,090 --> 00:15:00,400
[NOISE] Um, so now,

308
00:15:00,400 --> 00:15:02,635
the question I want to pose to you [NOISE] is, ah,

309
00:15:02,635 --> 00:15:05,620
when you're brainstorming project ideas, you know, like, this idea,

310
00:15:05,620 --> 00:15:07,705
or some other idea, um,

311
00:15:07,705 --> 00:15:10,360
what are the things you would want to watch out for?

312
00:15:10,360 --> 00:15:12,940
Wha- what are the properties that you would want to be true

313
00:15:12,940 --> 00:15:16,165
in order for you to feel good proposing this as a,

314
00:15:16,165 --> 00:15:18,580
as a CS 230 Project, right?

315
00:15:18,580 --> 00:15:20,935
So why don't you take a minute and, and write this down.

316
00:15:20,935 --> 00:15:23,020
I think, ah, uh, uh, yeah.

317
00:15:23,020 --> 00:15:25,975
Well, wha- wha- what if, if you're asking a friend if, if a friend is asking you,

318
00:15:25,975 --> 00:15:29,515
"What are the things I should look at to see if something is [NOISE] a good project?"

319
00:15:29,515 --> 00:15:32,200
What would you, what would you recommend to them?

320
00:15:32,200 --> 00:15:34,120
So, fe- few, just write down a few key words,

321
00:15:34,120 --> 00:15:36,730
and then we'll see what people say.

322
00:15:36,730 --> 00:15:39,130
And then, and then, I'll tell you what I tend to

323
00:15:39,130 --> 00:15:41,350
look out for when I'm selecting projects.

324
00:15:41,350 --> 00:15:44,990
And I have a list of, ah, five points.

325
00:15:51,170 --> 00:15:53,410
Might take like, I don't know,

326
00:15:53,410 --> 00:15:54,805
like, two minutes to-

327
00:15:54,805 --> 00:15:55,780
That's not activated.

328
00:15:55,780 --> 00:15:56,470
Yeah.

329
00:15:56,470 --> 00:15:59,230
Oh. Sorry. This is not activated?

330
00:15:59,230 --> 00:16:05,200
Um, uh, you're not able to answer this up, enter answers?

331
00:16:05,200 --> 00:16:10,490
Okay. [NOISE] Let me test the Internet access.

332
00:16:12,210 --> 00:16:14,500
Just, [NOISE] just checking it.

333
00:16:14,500 --> 00:16:15,895
Yeah. I'm connected to the Internet.

334
00:16:15,895 --> 00:16:18,010
Uh, [NOISE] Aarti, any ideas?

335
00:16:18,010 --> 00:16:20,140
[NOISE]

336
00:16:20,140 --> 00:16:20,920
It was just activated.

337
00:16:20,920 --> 00:16:23,440
Oh, I see. Okay. All right.

338
00:16:23,440 --> 00:16:27,760
Let me try that. [NOISE] I'll just.

339
00:16:27,760 --> 00:16:28,930
Turn it on. [OVERLAPPING]

340
00:16:28,930 --> 00:16:30,520
Oh, it's working now? Okay. Thank you. [OVERLAPPING]

341
00:16:30,520 --> 00:16:32,860
Maybe I'll turn off to do it,

342
00:16:32,860 --> 00:16:35,170
but it keeps getting turning off.

343
00:16:35,170 --> 00:16:35,830
Okay. Yes. Thank you.

344
00:16:35,830 --> 00:16:40,360
[NOISE]

345
00:16:40,360 --> 00:16:55,030
Yeah.

346
00:16:55,030 --> 00:17:09,040
Thanks.

347
00:17:09,040 --> 00:17:12,010
[NOISE] So, if you take,

348
00:17:12,010 --> 00:17:14,335
like, two minutes to enter, and I think,

349
00:17:14,335 --> 00:17:17,140
I think I can figure this and let you enter multiple answers.

350
00:17:17,140 --> 00:17:18,190
Let me just take two minutes.

351
00:17:18,190 --> 00:17:51,940
[NOISE]

352
00:18:07,190 --> 00:18:09,390
All right, another one minute.

353
00:18:09,390 --> 00:18:36,630
[NOISE]

354
00:18:36,630 --> 00:18:39,550
All right, 30 seconds.

355
00:19:04,460 --> 00:19:07,980
Okay, three, two, one.

356
00:19:07,980 --> 00:19:16,090
Well, maybe in the hindsight that wasn't the best visualization.

357
00:19:16,580 --> 00:19:18,600
Can people see this?

358
00:19:18,600 --> 00:19:39,990
[NOISE]

359
00:19:39,990 --> 00:19:42,420
Um nevermind, trying to see if- all right so,

360
00:19:42,420 --> 00:19:44,925
data novelty, loss of data,

361
00:19:44,925 --> 00:19:47,130
some of these are very small, human doable,

362
00:19:47,130 --> 00:19:48,780
number of examples, do one,

363
00:19:48,780 --> 00:19:50,535
two ones [inaudible] algorithm,

364
00:19:50,535 --> 00:19:52,665
new industry of fields, uh,

365
00:19:52,665 --> 00:19:58,050
clear objective, practical useful, huh,

366
00:19:58,050 --> 00:20:05,070
oh, finishing time, uh, [LAUGHTER].

367
00:20:05,070 --> 00:20:06,420
Host real life problem,

368
00:20:06,420 --> 00:20:09,600
useful hasn't been done [inaudible] tractable.

369
00:20:09,600 --> 00:20:16,020
Yeah. Generalization [inaudible] Um,

370
00:20:16,020 --> 00:20:18,450
let me make some comments on these.

371
00:20:18,450 --> 00:20:19,620
I think I, this is,

372
00:20:19,620 --> 00:20:21,030
this is pretty good, um.

373
00:20:21,030 --> 00:20:23,670
I have a list of five bullet points and maybe I just share

374
00:20:23,670 --> 00:20:26,400
of you my list of five, uh, um,

375
00:20:26,400 --> 00:20:27,540
[NOISE] which is I'm,

376
00:20:27,540 --> 00:20:32,445
just some things to encourage you to pay attention to, um, you know.

377
00:20:32,445 --> 00:20:34,440
This, this may or may not be the best criteria,

378
00:20:34,440 --> 00:20:35,835
but interests I think, well,

379
00:20:35,835 --> 00:20:37,920
interests plus, uh, I just hopefully you

380
00:20:37,920 --> 00:20:40,530
work on something that you're actually interested in, um.

381
00:20:40,530 --> 00:20:45,630
And then I think, uh, uh, right,

382
00:20:45,630 --> 00:20:49,320
data availability which many of you cited is a good criteria or,

383
00:20:49,320 --> 00:20:50,880
uh, wanted the ways that,

384
00:20:50,880 --> 00:20:54,315
um, Stanford class projects sometimes do not go well,

385
00:20:54,315 --> 00:20:57,090
is its students spend a month trying to collect data and after month

386
00:20:57,090 --> 00:21:00,120
have not yet found the data and then- and then,

387
00:21:00,120 --> 00:21:01,635
you know, and then there's uh,

388
00:21:01,635 --> 00:21:03,750
and then there's a lot of wasted time.

389
00:21:03,750 --> 00:21:07,860
Um, one thing that I would encourage

390
00:21:07,860 --> 00:21:14,265
you to consider as well is,

391
00:21:14,265 --> 00:21:16,290
uh, domain knowledge, um.

392
00:21:16,290 --> 00:21:20,430
And I think that if you are a biologist and have

393
00:21:20,430 --> 00:21:22,290
unique knowledge into some aspect of

394
00:21:22,290 --> 00:21:24,720
biology through which you want to apply Machine learning,

395
00:21:24,720 --> 00:21:27,840
that will actually let you do a very interesting project, right.

396
00:21:27,840 --> 00:21:31,200
That- that is is actually difficult for others to do.

397
00:21:31,200 --> 00:21:33,000
Um, and I think, uh,

398
00:21:33,000 --> 00:21:36,720
more generally as, as a advice for navigating your careers, right.

399
00:21:36,720 --> 00:21:38,670
So, you know, i- its interesting because you know,

400
00:21:38,670 --> 00:21:40,335
Machine learning, Deep learning, there's so much,

401
00:21:40,335 --> 00:21:44,175
there's so many people wanting to jump into Machine learning and Deep learning,

402
00:21:44,175 --> 00:21:46,110
um, actually I'll give you an example.

403
00:21:46,110 --> 00:21:48,360
So, I sometimes talk to, uh, uh, doctors,

404
00:21:48,360 --> 00:21:51,240
Radiology students, uh, uh, including, you know,

405
00:21:51,240 --> 00:21:52,980
like Stanford and other universities

406
00:21:52,980 --> 00:21:56,700
Radiology students that want to learn about Machine learning, right?

407
00:21:56,700 --> 00:21:58,455
Because they hear about, you know, Deep learning,

408
00:21:58,455 --> 00:22:00,630
maybe someday affecting radiologist jobs,

409
00:22:00,630 --> 00:22:02,340
and so they want to be part of Deep learning.

410
00:22:02,340 --> 00:22:05,805
And so my career advice to them is usually

411
00:22:05,805 --> 00:22:10,170
to not forget everything they learned as a doctor and try to,

412
00:22:10,170 --> 00:22:13,260
you know, do Machine learning 101 from scratch and just

413
00:22:13,260 --> 00:22:16,470
forget everything they learned as a doctor and just become a CS major.

414
00:22:16,470 --> 00:22:18,570
I think that- that path can work,

415
00:22:18,570 --> 00:22:22,365
but I think where radiologists could do the most unique work,

416
00:22:22,365 --> 00:22:25,170
uh, that allows them to make a most unique contribution,

417
00:22:25,170 --> 00:22:27,270
is that they use their domain knowledge of

418
00:22:27,270 --> 00:22:30,765
healthcare radiology and do something in Machine learning applied to radiology,

419
00:22:30,765 --> 00:22:32,760
right, uh, and so,

420
00:22:32,760 --> 00:22:35,910
was [LAUGHTER] all right.

421
00:22:35,910 --> 00:22:39,690
[LAUGHTER] How, how many- how many millennials are there in this class?

422
00:22:39,690 --> 00:22:43,050
[LAUGHTER] What is that me,

423
00:22:43,050 --> 00:22:45,780
me, me, me, me thing? [LAUGHTER] All right.

424
00:22:46,730 --> 00:22:52,895
All right. This is really wrong.

425
00:22:52,895 --> 00:22:55,955
Yeah. [LAUGHTER] I- I think it's because this is a word cloud.

426
00:22:55,955 --> 00:22:57,410
So they count word frequency,

427
00:22:57,410 --> 00:22:59,625
right? The money thing.

428
00:22:59,625 --> 00:23:05,415
I don't know, I have very mixed feelings about that [LAUGHTER]. All right.

429
00:23:05,415 --> 00:23:06,510
Um, but I think as,

430
00:23:06,510 --> 00:23:09,210
[inaudible] I actually know that some of you are taking, you know,

431
00:23:09,210 --> 00:23:11,760
Deep learning because you work in a different discipline and

432
00:23:11,760 --> 00:23:14,340
you want to do something in this hot, new,

433
00:23:14,340 --> 00:23:16,290
exciting thing of Machine learning and I think,

434
00:23:16,290 --> 00:23:17,805
uh, whatever this major you're in,

435
00:23:17,805 --> 00:23:20,085
if your domain knowledge about some other area,

436
00:23:20,085 --> 00:23:22,815
you know, Education, Civil Engineering, Biology, Law.

437
00:23:22,815 --> 00:23:25,650
Um, taking Deep learning allows you to do

438
00:23:25,650 --> 00:23:28,500
very unique work applying Machine learning to your domain,

439
00:23:28,500 --> 00:23:32,160
right, um, [NOISE] uh. Let's see.

440
00:23:32,160 --> 00:23:33,585
Um, I think that, uh,

441
00:23:33,585 --> 00:23:38,565
uh, um, [NOISE] um,

442
00:23:38,565 --> 00:23:41,730
I think, well, I call the utility but several of you mentioned as well,

443
00:23:41,730 --> 00:23:44,040
something that has a positive impact that actually helps other people,

444
00:23:44,040 --> 00:23:45,930
uh, uh, uh, and,

445
00:23:45,930 --> 00:23:49,470
and I- I- I don't know money could be an aspect of utility,

446
00:23:49,470 --> 00:23:51,900
but maybe not, the most inspiring one uh,

447
00:23:51,900 --> 00:23:53,760
and then I think, um,

448
00:23:53,760 --> 00:24:02,010
[NOISE] and I think one of the biggest challenges we face in the industry today is still,

449
00:24:02,010 --> 00:24:05,175
frankly, is actually good judgment on feasibility, um.

450
00:24:05,175 --> 00:24:09,840
So today, I still see too many, uh, leaders,

451
00:24:09,840 --> 00:24:12,600
sometimes CEOs of large companies that stand

452
00:24:12,600 --> 00:24:15,240
on stage and announce to the whole world, you know,

453
00:24:15,240 --> 00:24:17,070
we're gonna do this Machine learning project,

454
00:24:17,070 --> 00:24:20,475
to do this by this deadline and then 20 minutes later,

455
00:24:20,475 --> 00:24:24,945
I talk to their engineers and the engineers say nope, no way,

456
00:24:24,945 --> 00:24:27,390
not happening what the [LAUGHTER] CEO just finally says [LAUGHTER]

457
00:24:27,390 --> 00:24:30,120
whole engineering [inaudible] is not doing that and knows that it's impossible.

458
00:24:30,120 --> 00:24:33,600
So, I think one of the biggest challenges is actually feasibility um,

459
00:24:33,600 --> 00:24:35,640
in fact, I actually know that's a- a- a you know,

460
00:24:35,640 --> 00:24:37,860
I was chatting with Aarti about, uh, the, the,

461
00:24:37,860 --> 00:24:40,890
um, uh TA office hours and I know that, uh,

462
00:24:40,890 --> 00:24:42,390
uh there been lot of,

463
00:24:42,390 --> 00:24:43,845
you know, a lot of you have been, uh,

464
00:24:43,845 --> 00:24:45,315
thinking about applying, uh,

465
00:24:45,315 --> 00:24:46,845
end-to-end Deep learning, right?

466
00:24:46,845 --> 00:24:49,740
You know. Can you input any x and output any y and

467
00:24:49,740 --> 00:24:52,860
do that accurately and sometimes it's possible and sometimes it's not,

468
00:24:52,860 --> 00:24:55,470
and it still takes, uh, relatively deep,

469
00:24:55,470 --> 00:24:59,820
deep judgment about what neural networks can and cannot do with a certain amount of

470
00:24:59,820 --> 00:25:01,650
data that you may or may not be able to

471
00:25:01,650 --> 00:25:04,530
acquire in order to do some of these things, right?

472
00:25:04,530 --> 00:25:07,635
Um, so- so, I think throughout this quarter,

473
00:25:07,635 --> 00:25:12,780
you gain much deeper judgment as well on on what is feasible, I guess.

474
00:25:12,780 --> 00:25:16,065
[NOISE] This is pretty interesting.

475
00:25:16,065 --> 00:25:18,840
I once know, uh, uh, uh I- I- I knew a CEO of a ve- very,

476
00:25:18,840 --> 00:25:21,870
of a large company that once told his team,

477
00:25:21,870 --> 00:25:24,930
um, uh, he actually gave this team these instructions.

478
00:25:24,930 --> 00:25:28,560
He said, uh, I wish they assume that AI can do anything,

479
00:25:28,560 --> 00:25:30,855
uh, and- and- and uh, uh,

480
00:25:30,855 --> 00:25:33,795
I think tha- tha- that had an interesting effect, I guess.

481
00:25:33,795 --> 00:25:36,675
Uh, uh, uh, yeah.

482
00:25:36,675 --> 00:25:38,295
Cool. All right.

483
00:25:38,295 --> 00:25:40,680
So, I think step one, um,

484
00:25:40,680 --> 00:25:42,210
was select a project,

485
00:25:42,210 --> 00:25:43,410
I hope this is [inaudible] projects,

486
00:25:43,410 --> 00:25:45,525
try to keep some of those things in mind, um.

487
00:25:45,525 --> 00:25:49,990
Step two is get data, right, [NOISE] um.

488
00:25:51,680 --> 00:25:56,535
And so, uh, what I want you to do,

489
00:25:56,535 --> 00:25:58,350
uh, and I'm going to pose the second question

490
00:25:58,350 --> 00:25:59,775
and then have some you discuss this.

491
00:25:59,775 --> 00:26:02,910
Let's say that you're actually working on this, you know,

492
00:26:02,910 --> 00:26:07,095
smarts voice-activated embedded devices thing, right?

493
00:26:07,095 --> 00:26:10,020
So let's say that you and your friends wanna build a start up so

494
00:26:10,020 --> 00:26:12,930
train a deep learning algorithm to detect, you know,

495
00:26:12,930 --> 00:26:17,175
phrases like John turned on or Mary turn off or Bob turn off or whatever, uh,

496
00:26:17,175 --> 00:26:19,770
to sell to device makers so that they

497
00:26:19,770 --> 00:26:22,260
can have low voice [NOISE] embedded voice detection chip.

498
00:26:22,260 --> 00:26:26,175
It doesn't require a complicated Wi-Fi setup process, right?

499
00:26:26,175 --> 00:26:28,320
So let's see one of- let's see how she wanna do this.

500
00:26:28,320 --> 00:26:30,990
So, you need to collect some data in order

501
00:26:30,990 --> 00:26:33,495
to start training a learning algorithm, all right?

502
00:26:33,495 --> 00:26:37,740
So, uh, the second question I would pose to you is, uh, uh,

503
00:26:37,740 --> 00:26:40,260
uh, two- a question in two parts uh,

504
00:26:40,260 --> 00:26:42,165
but, but, uh, have you answer it all,

505
00:26:42,165 --> 00:26:43,485
all at the same time which is,

506
00:26:43,485 --> 00:26:45,825
uh, in how many, how many days,

507
00:26:45,825 --> 00:26:47,490
let's say you actually proposed this for

508
00:26:47,490 --> 00:26:51,150
your CS 230 project this Sunday and then you start work on it,

509
00:26:51,150 --> 00:26:52,290
you know, like on Monday.

510
00:26:52,290 --> 00:26:54,795
Are you guys start work on it today before the proposal?

511
00:26:54,795 --> 00:26:58,410
But, uh, how many days would you spend collecting data?

512
00:26:58,410 --> 00:27:00,555
Uh, and how would you collect data?

513
00:27:00,555 --> 00:27:03,090
Okay? And I think, um, I'm actually how,

514
00:27:03,090 --> 00:27:06,450
how many of you have participated in Engineering Scrum?

515
00:27:06,450 --> 00:27:07,980
If you know what that means?

516
00:27:07,980 --> 00:27:10,050
Okay a few of you uh, those who have an industry.

517
00:27:10,050 --> 00:27:12,405
Okay, all right so engineering estimation,

518
00:27:12,405 --> 00:27:15,870
when you estimate how long a project takes one of the common practices is

519
00:27:15,870 --> 00:27:19,845
use a Fibonacci sequence to estimate how long a project will take, right?

520
00:27:19,845 --> 00:27:22,935
And so Fibonacci sequence one, one, two,

521
00:27:22,935 --> 00:27:28,275
three, five, eight,13 and so on.

522
00:27:28,275 --> 00:27:30,750
And this roughly powers of two- but doesn't grow as fast as

523
00:27:30,750 --> 00:27:33,675
powers to Fibonacci numbers are cool, right.

524
00:27:33,675 --> 00:27:35,235
For so- uh, uh, so,

525
00:27:35,235 --> 00:27:40,360
so what I want you to do is just finish after configuration right.

526
00:27:47,990 --> 00:27:53,385
When our, um, speech bubbles, okay.

527
00:27:53,385 --> 00:27:56,910
Yeah, that's good. All right.

528
00:27:56,910 --> 00:27:59,190
So what I'd like you to do is in the text answer,

529
00:27:59,190 --> 00:28:00,330
uh, I really write two things,

530
00:28:00,330 --> 00:28:01,875
one is write a number,

531
00:28:01,875 --> 00:28:04,380
how many days do you think you spent on collecting data?

532
00:28:04,380 --> 00:28:06,540
You and your teammates if you're actually doing this project.

533
00:28:06,540 --> 00:28:07,845
Uh, and then how,

534
00:28:07,845 --> 00:28:09,870
how would you go about collecting the data?

535
00:28:09,870 --> 00:28:14,220
Okay? So once you take good, another two minutes,

536
00:28:14,220 --> 00:28:19,140
uh, to write in an answer.

537
00:28:19,140 --> 00:28:26,655
[NOISE] Oh I'm sorry.

538
00:28:26,655 --> 00:28:31,710
This heavy load, now still not activated.

539
00:28:40,250 --> 00:28:44,565
So then try to hit, uh, interesting.

540
00:28:44,565 --> 00:28:47,410
That is not helpful.

541
00:28:53,630 --> 00:28:57,670
All right, that is definitely not helpful.

542
00:29:02,570 --> 00:29:05,655
Um. All right, let's do this,

543
00:29:05,655 --> 00:29:10,560
write down your answer on a piece of paper first and take two minutes [inaudible 29:10].

544
00:29:10,560 --> 00:29:11,865
So the two questions are,

545
00:29:11,865 --> 00:29:13,425
are how many days?

546
00:29:13,425 --> 00:29:17,535
Uh, pick a number from a Fibonacci sequence and,

547
00:29:17,535 --> 00:29:19,065
uh, are you going to use it nothing?

548
00:29:19,065 --> 00:29:22,005
Oh, okay, uh, let's swap out my computer for Aarti's.

549
00:29:22,005 --> 00:29:23,490
Oh actually, yeah oh,

550
00:29:23,490 --> 00:29:26,700
if Aarti's computers working, actually go ahead.

551
00:29:26,700 --> 00:29:29,910
Sorry. Okay I can just present.

552
00:29:29,910 --> 00:29:31,950
Yeah, yeah let's, let's plug in your laptop? Shall we?

553
00:29:31,950 --> 00:29:38,430
So you just use your laptop. [NOISE] See, sure.

554
00:29:38,430 --> 00:29:45,720
Yeah. Yeah. Doesn't say I wonder if there's a network problem or web browser problem.

555
00:29:45,720 --> 00:29:48,525
Uh, I started using uh,

556
00:29:48,525 --> 00:29:52,800
Firefox recently in addition to Chrome and Safari and that was Firefox,

557
00:29:52,800 --> 00:29:55,510
I've tried with other web browsers later.

558
00:29:59,720 --> 00:30:02,235
Right, cool. Okay, okay, thank you.

559
00:30:02,235 --> 00:30:05,280
Thanks all to you. [NOISE].

560
00:30:05,280 --> 00:30:10,485
All right. I can maybe,

561
00:30:10,485 --> 00:30:13,260
yeah maybe people then take another minute from now,

562
00:30:13,260 --> 00:30:16,170
just extend the time a bit to end.

563
00:31:04,490 --> 00:31:07,960
All right. Now the 10 seconds.

564
00:31:15,860 --> 00:31:18,890
All right, cool. Let's see,

565
00:31:18,890 --> 00:31:21,720
uh, show people's answers, okay?

566
00:31:23,740 --> 00:31:32,355
Right. Well, three hundred sixty-five

567
00:31:32,355 --> 00:31:33,930
So, there's a, there's a,

568
00:31:33,930 --> 00:31:37,090
there's a lot of variance in the answers, right?

569
00:31:42,620 --> 00:31:46,035
Uh, [LAUGHTER] Download from online depends on what data you want.

570
00:31:46,035 --> 00:31:47,100
It turns out well.

571
00:31:47,100 --> 00:31:50,730
So if you're trying to find data or phrases like John turn on that,

572
00:31:50,730 --> 00:31:52,260
that, that data doesn't exist online.

573
00:31:52,260 --> 00:31:56,100
Uh, it turns out that we're trying to find audio clips at the web activate.

574
00:31:56,100 --> 00:31:57,795
There are some websites with, uh,

575
00:31:57,795 --> 00:32:00,345
single words pronounce but those- but uh,

576
00:32:00,345 --> 00:32:02,340
not a lot of audio clips session so

577
00:32:02,340 --> 00:32:04,530
the trigger world where the wake word is the word activate.

578
00:32:04,530 --> 00:32:07,440
Uh, there are some websites we can download like,

579
00:32:07,440 --> 00:32:11,430
maybe 10 audio clips of a few people saying activate but it's quite

580
00:32:11,430 --> 00:32:15,840
hard to find hundreds of examples of different people saying the word activate.

581
00:32:15,840 --> 00:32:17,710
Um.

582
00:32:23,750 --> 00:32:26,370
Five days it falls from the sky.

583
00:32:26,370 --> 00:32:34,665
[LAUGHTER] All right, so,

584
00:32:34,665 --> 00:32:37,020
let me suggest, um,

585
00:32:37,020 --> 00:32:41,940
uh- let me suggest that you guys discuss with each other in small groups,

586
00:32:41,940 --> 00:32:44,160
uh, what you think would be the best strategy?

587
00:32:44,160 --> 00:32:47,085
How many days we find collecting the data and how we decide collecting data?

588
00:32:47,085 --> 00:32:49,785
Try convince people next to you on that.

589
00:32:49,785 --> 00:32:52,665
Uh, and, and before I ask you to start discussing,

590
00:32:52,665 --> 00:32:55,035
I wanna leave you with one thought which is, um,

591
00:32:55,035 --> 00:32:58,275
how long do you think will take you to train your first model?

592
00:32:58,275 --> 00:33:03,360
Right. And so if it take you a day to train your first model or two days?

593
00:33:03,360 --> 00:33:08,550
Uh, do you want to spend x time collecting data and then spend let's say,

594
00:33:08,550 --> 00:33:10,560
you know, I'll know to [inaudible] the deep learning thing,

595
00:33:10,560 --> 00:33:12,390
train a model, it might take a couple of days, right?

596
00:33:12,390 --> 00:33:14,670
Especially if you've download open source packages, so,

597
00:33:14,670 --> 00:33:17,370
so the amount of time needed to collect data as

598
00:33:17,370 --> 00:33:20,565
x followed by two days to train your first model,

599
00:33:20,565 --> 00:33:22,680
what do you think x should be the amount of time?

600
00:33:22,680 --> 00:33:24,840
Once you go spend like two minutes to discuss with each

601
00:33:24,840 --> 00:33:27,300
other and see if you can, can the, the,

602
00:33:27,300 --> 00:33:28,500
the answers are- there is

603
00:33:28,500 --> 00:33:31,365
very large variance right once you guys discuss, if you actually, if,

604
00:33:31,365 --> 00:33:33,330
if the people sitting next to you are your project partners,

605
00:33:33,330 --> 00:33:34,815
why should you discuss with them how,

606
00:33:34,815 --> 00:33:38,475
how many days you think you should spend collecting data and how you collect the data?

607
00:33:38,475 --> 00:33:41,160
Okay? Why don't you  take two minutes to discuss a little.

608
00:33:41,160 --> 00:35:42,640
[NOISE]

609
00:35:42,640 --> 00:35:53,340
All right.

610
00:35:53,340 --> 00:35:54,205
[NOISE] All right guys.

611
00:35:54,205 --> 00:35:59,440
So, [NOISE] wow, all right guys.

612
00:35:59,440 --> 00:36:02,305
[LAUGHTER] Hey guys.

613
00:36:02,305 --> 00:36:06,010
So, [NOISE] all right.

614
00:36:06,010 --> 00:36:08,530
A lot of exciting discussion.

615
00:36:08,530 --> 00:36:11,425
So, actually how, how many of you,

616
00:36:11,425 --> 00:36:14,440
how many of the groups wound up on the, on the low end?

617
00:36:14,440 --> 00:36:16,150
How many of you, you know,

618
00:36:16,150 --> 00:36:18,730
convinced each other that maybe it should be,

619
00:36:18,730 --> 00:36:21,115
like, three days or less?

620
00:36:21,115 --> 00:36:23,905
Oh, just a few of you. How come?

621
00:36:23,905 --> 00:36:26,530
Some, some- someone, someone say why?

622
00:36:26,530 --> 00:36:27,595
Why is it, why, why?

623
00:36:27,595 --> 00:36:32,215
Because you wanted us to see if the algorithm works first.

624
00:36:32,215 --> 00:36:36,790
So, we need some direction to just test to see if the algorithm is even reaching

625
00:36:36,790 --> 00:36:41,905
some sort of good benchmark before we then go and collect the next data set.

626
00:36:41,905 --> 00:36:44,290
Cool, yeah, right. I guess a little bit of data to test how

627
00:36:44,290 --> 00:36:47,290
the algorithm works before you even go and collect the next data set, all right?

628
00:36:47,290 --> 00:36:49,570
Cool. And did anyone had a,

629
00:36:49,570 --> 00:36:53,170
had a high-end, like a 13 days or more?Yes.

630
00:36:53,170 --> 00:36:54,730
Very few. How come?

631
00:36:54,730 --> 00:36:56,440
Anyone, actually anyone, anyone with

632
00:36:56,440 --> 00:36:59,185
insights you want to share with the whole class if you,

633
00:36:59,185 --> 00:37:02,290
what, what were you all discussing so excitedly?

634
00:37:02,290 --> 00:37:10,015
[LAUGHTER]. Yeah, go ahead.

635
00:37:10,015 --> 00:37:13,030
So, um, depending on domain knowledge, uh,

636
00:37:13,030 --> 00:37:15,790
maybe a connection can take a long time especially for this problem,

637
00:37:15,790 --> 00:37:19,645
like, based on that one idea which we discussed in previous class, we were thinking like,

638
00:37:19,645 --> 00:37:21,730
we could use like, movie clips and like,

639
00:37:21,730 --> 00:37:24,220
some typos to like, generate sound like,

640
00:37:24,220 --> 00:37:30,745
[inaudible] And that will take like time to like

641
00:37:30,745 --> 00:37:39,190
mine data, um, [inaudible] [NOISE],

642
00:37:39,190 --> 00:37:40,270
Yeah, yeah, yeah, right.

643
00:37:40,270 --> 00:37:43,419
Yeah. So, there are accompanying systems to look at subtitle,

644
00:37:43,419 --> 00:37:45,070
uh, uh, videos, right?

645
00:37:45,070 --> 00:37:46,090
Uh, uh, like, uh,

646
00:37:46,090 --> 00:37:47,830
YouTube videos with captions or something and,

647
00:37:47,830 --> 00:37:49,720
and if there's, uh, appropriately,

648
00:37:49,720 --> 00:37:51,400
creative commons data there you can use.

649
00:37:51,400 --> 00:37:52,945
Yeah. So, let me,

650
00:37:52,945 --> 00:37:54,190
let me tell you my bias.

651
00:37:54,190 --> 00:37:58,120
I, I- I'll just tell you what I would do if I was working on this project.

652
00:37:58,120 --> 00:37:59,620
Well, as, well, one caveat,

653
00:37:59,620 --> 00:38:02,290
I haven't done so much work in speech recognition previously, right?

654
00:38:02,290 --> 00:38:03,535
This is my first project.

655
00:38:03,535 --> 00:38:08,500
Um, I would probably spend 1-2 days collecting data [NOISE],

656
00:38:08,500 --> 00:38:10,630
kind of, on the short end, right?

657
00:38:10,630 --> 00:38:14,035
And I think that, you know, one of the,

658
00:38:14,035 --> 00:38:17,605
and, and, and one of the reasons is that Machine Learning,

659
00:38:17,605 --> 00:38:23,125
kind of that circle I drew up there is actually a very iterative process where,

660
00:38:23,125 --> 00:38:25,570
um, until you try it, you,

661
00:38:25,570 --> 00:38:30,400
you almost never know what's actually going to be hard about the problem, right?

662
00:38:30,400 --> 00:38:33,010
And so, um, so if I was doing this project,

663
00:38:33,010 --> 00:38:34,300
I'll just tell you honestly what I would do.

664
00:38:34,300 --> 00:38:36,655
Like, again, I've actually thought about this project a bunch, right?

665
00:38:36,655 --> 00:38:39,370
Including, you know, trying to validate market acceptance and so on.

666
00:38:39,370 --> 00:38:41,725
But, um, but which is that, um,

667
00:38:41,725 --> 00:38:44,650
I would get a cheap microphone, a user or,

668
00:38:44,650 --> 00:38:48,355
or user built-in laptop microphone or buy a microphone off, you know,

669
00:38:48,355 --> 00:38:52,255
buy a microphone off Amazon or something and go around say,

670
00:38:52,255 --> 00:38:55,390
go around Stanford campus or go to your friends and have them just say, "Hey,

671
00:38:55,390 --> 00:38:58,840
do you mind saying into this microphone the word activate or John,

672
00:38:58,840 --> 00:39:02,905
turn on or whatever," and collect a bunch of data that way.

673
00:39:02,905 --> 00:39:05,890
Um, and then, uh,

674
00:39:05,890 --> 00:39:09,430
uh, and with one or two days, um,

675
00:39:09,430 --> 00:39:13,270
you should be able to collect at least hundreds of examples, uh,

676
00:39:13,270 --> 00:39:16,180
and that might be enough of the data set to start

677
00:39:16,180 --> 00:39:19,420
training a rudimentary learning algorithm to get going.

678
00:39:19,420 --> 00:39:22,855
Because if you have not yet worked on this problem before,

679
00:39:22,855 --> 00:39:27,250
it turns out to be very difficult to know what's going to be hard about the problem.

680
00:39:27,250 --> 00:39:28,780
So, is what's gonna be hard, um,

681
00:39:28,780 --> 00:39:31,225
highly accented speakers, right?

682
00:39:31,225 --> 00:39:34,510
Uh, or is what's gonna be hard background noise, um,

683
00:39:34,510 --> 00:39:36,205
or is what's gonna be hard, you know,

684
00:39:36,205 --> 00:39:38,065
confusing turn on with turn off?

685
00:39:38,065 --> 00:39:44,184
You hear John turn and then [NOISE] But when you build a new Machine Learning system,

686
00:39:44,184 --> 00:39:48,800
it's very difficult to know what's hard and what's easy about the problem, uh,

687
00:39:48,800 --> 00:39:52,060
or or is what's gonna be difficult that far-field, which is,

688
00:39:52,060 --> 00:39:55,630
um, the technical term for if the microphone is very far away, right?

689
00:39:55,630 --> 00:39:56,890
So, it turns out that, you know,

690
00:39:56,890 --> 00:39:58,315
if, if we turn on the, um,

691
00:39:58,315 --> 00:40:00,430
microphone on my laptop now for example,

692
00:40:00,430 --> 00:40:02,440
um, the, the laptop,

693
00:40:02,440 --> 00:40:04,675
which is what, like three meters away from me, uh,

694
00:40:04,675 --> 00:40:10,380
will be hearing voice directly from my mouth as well as voice bouncing off the walls.

695
00:40:10,380 --> 00:40:12,120
[NOISE] So, there's a lot of reverberation in this room

696
00:40:12,120 --> 00:40:14,055
and so that makes speech recognition harder.

697
00:40:14,055 --> 00:40:16,620
You, me are so good at processing out reverberant sounds,

698
00:40:16,620 --> 00:40:19,035
reverberations that you almost don't notice it,

699
00:40:19,035 --> 00:40:20,805
but it may, i- it actually the,

700
00:40:20,805 --> 00:40:22,840
but the learning algorithm will have,

701
00:40:22,840 --> 00:40:25,270
sometimes has problems with reverberations, right?

702
00:40:25,270 --> 00:40:27,820
Or echos bouncing off the hard walls of this room.

703
00:40:27,820 --> 00:40:32,680
Um, and so depending on what your learning algorithm has trouble with,

704
00:40:32,680 --> 00:40:35,320
um, you will then want to go back to collect

705
00:40:35,320 --> 00:40:38,470
very different types of data or explore very different types of algorithms.

706
00:40:38,470 --> 00:40:42,190
Well, the problem is that sometimes is because just the volume is just too soft,

707
00:40:42,190 --> 00:40:43,690
in which case, you know, maybe you need to do

708
00:40:43,690 --> 00:40:45,550
something else and normalize all your volumes,

709
00:40:45,550 --> 00:40:47,185
or buy a more sensitive microphone or something.

710
00:40:47,185 --> 00:40:50,290
So, it turns out that when building most Machine Learning applications,

711
00:40:50,290 --> 00:40:52,645
unless you've experienced working on it.

712
00:40:52,645 --> 00:40:54,580
So, I- I've actually worked on this problem before,

713
00:40:54,580 --> 00:40:56,140
so I have a sense of what's hard and what's easy.

714
00:40:56,140 --> 00:40:58,045
But when you work on a new project for the first time,

715
00:40:58,045 --> 00:41:00,130
it's very difficult to know what's hard and what's easy.

716
00:41:00,130 --> 00:41:02,620
And so my advice to most teams is, um,

717
00:41:02,620 --> 00:41:06,145
rather than [NOISE] spending say

718
00:41:06,145 --> 00:41:12,010
20 days to collect data and then two days to collect model,

719
00:41:12,010 --> 00:41:13,390
to train a model,

720
00:41:13,390 --> 00:41:18,820
and it's often by training a model and then seeing what are the examples it gets wrong,

721
00:41:18,820 --> 00:41:20,305
when does the algorithm fail?

722
00:41:20,305 --> 00:41:23,830
That, that, that's your feedback to either collect

723
00:41:23,830 --> 00:41:27,850
more data or redesign the model, right?

724
00:41:27,850 --> 00:41:29,350
Or try something else.

725
00:41:29,350 --> 00:41:32,650
Um, and if you can shrink the data collection period

726
00:41:32,650 --> 00:41:37,225
down to be more comparable to how long you end up taking to train your model,

727
00:41:37,225 --> 00:41:41,005
then you can start iterating much more rapidly on,

728
00:41:41,005 --> 00:41:43,150
on actually improving your model, right?

729
00:41:43,150 --> 00:41:45,970
Uh, and uh, so maybe one rule of

730
00:41:45,970 --> 00:41:49,180
thumb I actually tend to recommend for most class projects is I know,

731
00:41:49,180 --> 00:41:51,055
if i- maybe if you need to spend a week,

732
00:41:51,055 --> 00:41:52,780
up to a week to collect data, you know,

733
00:41:52,780 --> 00:41:56,110
maybe that's okay, but if you can get it going even more quickly.

734
00:41:56,110 --> 00:42:00,850
Uh, uh, I would even maybe more strongly recommend that, um,

735
00:42:00,850 --> 00:42:03,730
and there have been so few examples in

736
00:42:03,730 --> 00:42:07,360
my life where the first time I trained a learning algorithm it worked, right?

737
00:42:07,360 --> 00:42:09,400
I- it like, pretty much never happens.

738
00:42:09,400 --> 00:42:13,450
Yeah, I, I, I, i- it happened once about a year ago and I was so surprised,

739
00:42:13,450 --> 00:42:14,770
I still remember that one time.

740
00:42:14,770 --> 00:42:18,190
[LAUGHTER] Uh, and so what, so,

741
00:42:18,190 --> 00:42:20,350
so Machine Learning development is often

742
00:42:20,350 --> 00:42:23,770
a very iterative process and by quickly collecting data set.

743
00:42:23,770 --> 00:42:27,445
And, and often data sets are collected through sweat and hard work, right?

744
00:42:27,445 --> 00:42:29,335
And so, I, I would literally,

745
00:42:29,335 --> 00:42:30,445
you know, and actually,

746
00:42:30,445 --> 00:42:31,780
well, I've actually done a long long speech.

747
00:42:31,780 --> 00:42:32,965
And to get it going quickly,

748
00:42:32,965 --> 00:42:35,065
I would probably just, um, uh,

749
00:42:35,065 --> 00:42:38,590
have myself or my team members run around and find

750
00:42:38,590 --> 00:42:42,400
people and ask them to speak into a microphone and record audio clips that way.

751
00:42:42,400 --> 00:42:44,800
Um, and then only when you validate that you need

752
00:42:44,800 --> 00:42:47,170
a bigger data set would you go to a more complicated things,

753
00:42:47,170 --> 00:42:49,840
like set up an Amazon Mechanical Turk thing, right?

754
00:42:49,840 --> 00:42:52,270
To crowdsource, which I've also done actually, right?

755
00:42:52,270 --> 00:42:55,780
I also had very large data sets collected off Amazon Mechanical Turk,

756
00:42:55,780 --> 00:42:58,150
but only in a later stage of the project where you

757
00:42:58,150 --> 00:43:01,015
understand what you really need, right?

758
00:43:01,015 --> 00:43:04,840
Um, so as you,

759
00:43:04,840 --> 00:43:06,580
as you start working on your class projects,

760
00:43:06,580 --> 00:43:09,010
maybe, maybe keep that, keep that in mind.

761
00:43:09,010 --> 00:43:28,750
So, now, um, [NOISE] so,

762
00:43:28,750 --> 00:43:31,300
one other tip that,

763
00:43:31,300 --> 00:43:32,590
uh, Machine Learning researchers,

764
00:43:32,590 --> 00:43:34,630
on average, we tend to be terrible at this,

765
00:43:34,630 --> 00:43:37,015
um, um, but I'll give this advice anyway,

766
00:43:37,015 --> 00:43:38,740
is when you're going through this process,

767
00:43:38,740 --> 00:43:40,975
getting data, design a model, uh,

768
00:43:40,975 --> 00:43:43,000
a literature search would be very helpful, you know,

769
00:43:43,000 --> 00:43:45,865
so see what other, see what algorithms others are using for this problem.

770
00:43:45,865 --> 00:43:47,845
It turns out the literature is actually quite immature.

771
00:43:47,845 --> 00:43:49,990
There isn't a convergence of,

772
00:43:49,990 --> 00:43:51,490
uh, like a world standard set,

773
00:43:51,490 --> 00:43:55,090
sta- standard algorithms for trigger word detection in literature right now,

774
00:43:55,090 --> 00:43:56,830
which people are still making up algorithms.

775
00:43:56,830 --> 00:43:58,480
So, if you, if you do a little survey,

776
00:43:58,480 --> 00:43:59,650
you find that to be the case,

777
00:43:59,650 --> 00:44:01,105
but you're training initial model.

778
00:44:01,105 --> 00:44:03,670
Um, and in most Machine Learning applications,

779
00:44:03,670 --> 00:44:05,440
you go through this process multiple times.

780
00:44:05,440 --> 00:44:09,460
So, one tip that I would recommend you do is, uh,

781
00:44:09,460 --> 00:44:16,910
keep clear notes, um, on the experiments you've run.

782
00:44:17,370 --> 00:44:21,790
Right. Because they'll often be as you train the model,

783
00:44:21,790 --> 00:44:25,390
you see oh this model works great on American accent of speakers,

784
00:44:25,390 --> 00:44:27,325
but not on British accent of speakers.

785
00:44:27,325 --> 00:44:29,020
Right. I- I- I was born in the UK,

786
00:44:29,020 --> 00:44:30,910
sometimes I use British accents for example.

787
00:44:30,910 --> 00:44:32,230
If you are from a different part of the world,

788
00:44:32,230 --> 00:44:35,050
you think of different global accents but since I'm from the UK,

789
00:44:35,050 --> 00:44:37,765
I'm- I'm just gonna pick on British accents I guess.

790
00:44:37,765 --> 00:44:41,455
Keep clear notes on the experiments run because what happens in

791
00:44:41,455 --> 00:44:43,900
every machine learning project is after awhile you

792
00:44:43,900 --> 00:44:46,765
have trained 30 models and then you and your team members are going,

793
00:44:46,765 --> 00:44:49,810
"Oh yeah, we tried that idea two weeks ago did it work and if you have

794
00:44:49,810 --> 00:44:52,930
clear notes from when you actually did that work two weeks ago,

795
00:44:52,930 --> 00:44:55,945
then you can refer back rather than have to rerun the experiments."

796
00:44:55,945 --> 00:44:58,915
Um, the other thing that some groups do is, um,

797
00:44:58,915 --> 00:45:03,310
have a spreadsheet that keeps track of what's the learning rate you use?

798
00:45:03,310 --> 00:45:04,510
What's the number of hidden units?

799
00:45:04,510 --> 00:45:05,830
What's this? What's this? What's this?

800
00:45:05,830 --> 00:45:07,540
Or, or, or, or cheaper than a,

801
00:45:07,540 --> 00:45:11,905
than a text document so that which will make it easier to refer back to,

802
00:45:11,905 --> 00:45:13,900
to know someone's you tried earlier.

803
00:45:13,900 --> 00:45:17,380
Um, this is one piece of commonly-given advice.

804
00:45:17,380 --> 00:45:18,670
This is one of those things that

805
00:45:18,670 --> 00:45:21,940
every machine learning person knows we should do this but on average,

806
00:45:21,940 --> 00:45:23,710
we're very bad at doing this but,

807
00:45:23,710 --> 00:45:26,425
but, but, but, but you could I don't know.

808
00:45:26,425 --> 00:45:29,950
But at the times, I've managed to keep good notes so that you save them

809
00:45:29,950 --> 00:45:34,060
all the time right to try to remember what exactly you tried two weeks ago.

810
00:45:34,060 --> 00:45:40,765
Okay. So, a lot of this class will be on this process of how to get data,

811
00:45:40,765 --> 00:45:44,110
develop the train data test the design the model, train the model.

812
00:45:44,110 --> 00:45:45,910
Eventually, test them all then iterate.

813
00:45:45,910 --> 00:45:47,755
Okay. So, a lot this classes on this.

814
00:45:47,755 --> 00:45:52,300
So, I wanna jump ahead. So, when you have a good enough model and you want to deploy it.

815
00:45:52,300 --> 00:45:54,730
Okay. So, step six,

816
00:45:54,730 --> 00:45:57,080
I guess is deployment.

817
00:45:57,150 --> 00:46:04,555
Now, um, um, this is er, uh, um,

818
00:46:04,555 --> 00:46:06,820
one of the reasons I want to step through

819
00:46:06,820 --> 00:46:09,130
this example going through a concrete example is

820
00:46:09,130 --> 00:46:11,260
I find that when you're learning about machine

821
00:46:11,260 --> 00:46:13,570
learning for the first time is often seeing,

822
00:46:13,570 --> 00:46:16,030
you know, what- what my team says called war stories

823
00:46:16,030 --> 00:46:17,830
kinda of stories or projects that, that,

824
00:46:17,830 --> 00:46:22,030
that others have built before that often provides the best learning experience.

825
00:46:22,030 --> 00:46:24,760
I think like I have built speech recognition systems.

826
00:46:24,760 --> 00:46:27,340
It took me like a year or two years for me to do it.

827
00:46:27,340 --> 00:46:30,070
So, I'm trying to so rather than, you know,

828
00:46:30,070 --> 00:46:32,260
having you spend two years of your life building

829
00:46:32,260 --> 00:46:34,840
speech systems and can summarize a war story.

830
00:46:34,840 --> 00:46:36,745
Right. To tell you what the process is like,

831
00:46:36,745 --> 00:46:40,855
I'm hoping that these concrete examples of what building these systems are like in,

832
00:46:40,855 --> 00:46:43,900
you know, large corporations that can help you accelerate

833
00:46:43,900 --> 00:46:47,020
your learnings without needing to get two years of on-the-job experience.

834
00:46:47,020 --> 00:46:49,295
You can just secure the salient points.

835
00:46:49,295 --> 00:46:52,455
Okay. Now, if you're deploying a system like this,

836
00:46:52,455 --> 00:46:55,020
one of the things, um, and this is actually true.

837
00:46:55,020 --> 00:46:57,240
This is actually a real phenomenon for deploying

838
00:46:57,240 --> 00:47:00,285
speech systems is you have the audio clip,

839
00:47:00,285 --> 00:47:02,014
you have a neural network,

840
00:47:02,014 --> 00:47:05,530
and then you know this will output zero,

841
00:47:05,530 --> 00:47:09,460
one and the neural networks that work well,

842
00:47:09,460 --> 00:47:11,365
will tend to be relatively large,

843
00:47:11,365 --> 00:47:12,610
right relatively large model.

844
00:47:12,610 --> 00:47:15,490
Larger than hidden units relatively high complexity.

845
00:47:15,490 --> 00:47:20,560
And, um, if you have some of the smart speakers in your home, um,

846
00:47:20,560 --> 00:47:24,340
you recognize that a lot of them are Edge devices as

847
00:47:24,340 --> 00:47:27,970
opposed to purely cloud computation, right?

848
00:47:27,970 --> 00:47:29,590
So we all know what the cloud is.

849
00:47:29,590 --> 00:47:32,365
Um, uh, and what an Edge device is.

850
00:47:32,365 --> 00:47:36,850
And Edge device is a smart speaker that's in your home or the cell phone in your wallet.

851
00:47:36,850 --> 00:47:40,780
So, Edge devices are you know the things that are close to

852
00:47:40,780 --> 00:47:42,430
the data as opposed to the cloud which is

853
00:47:42,430 --> 00:47:45,040
a giant service we have in our data centers, right?

854
00:47:45,040 --> 00:47:48,310
So, um, because of network latency,

855
00:47:48,310 --> 00:47:50,920
er, er, and, and,

856
00:47:50,920 --> 00:47:54,010
and because of privacy a lot of these computations are

857
00:47:54,010 --> 00:47:57,805
done on Edge devices like a smart speaker in your home or,

858
00:47:57,805 --> 00:48:03,910
er, er, like er, I guess Hey Siri or Okay Google can wake up your cell phone, right?

859
00:48:03,910 --> 00:48:08,665
And so, Edge devices have much lower computational budgets and much lower power budgets,

860
00:48:08,665 --> 00:48:11,290
limited battery life, much less powerful processes

861
00:48:11,290 --> 00:48:13,330
than we have in our cloud data centers.

862
00:48:13,330 --> 00:48:16,450
And so, it turns out that se- se

863
00:48:16,450 --> 00:48:20,395
serving up a very large neural network is quite difficult.

864
00:48:20,395 --> 00:48:22,315
Right? It's very difficult for,

865
00:48:22,315 --> 00:48:24,025
you know, a low-power,

866
00:48:24,025 --> 00:48:27,670
inexpensive microprocessor sitting on a smart speaking in your living room

867
00:48:27,670 --> 00:48:32,710
to run a very large neural network with a lot of hidden units and a lot parameters.

868
00:48:32,710 --> 00:48:43,430
And so, what is often done is to actually do this.

869
00:48:47,070 --> 00:48:56,455
Which is to input an audio clip and then have a much simpler algorithm.

870
00:48:56,455 --> 00:48:58,225
Uh, figure out if, you know,

871
00:48:58,225 --> 00:49:00,730
anyone is even talking, right?

872
00:49:00,730 --> 00:49:03,025
Because so the smart speaker, you know,

873
00:49:03,025 --> 00:49:05,530
in my living room hears silence most of the day, right?

874
00:49:05,530 --> 00:49:07,090
Because usually, just no one at home, right?

875
00:49:07,090 --> 00:49:08,575
There's no no voice.

876
00:49:08,575 --> 00:49:10,855
And then only if it hears, you know,

877
00:49:10,855 --> 00:49:17,575
someone talking then feed it to the big neural network that you've trained and ramp-up,

878
00:49:17,575 --> 00:49:24,055
use a larger power budget in order to classify 01.

879
00:49:24,055 --> 00:49:27,750
Okay. Um, this component goes by many different names, um,

880
00:49:27,750 --> 00:49:32,865
in- in reasonably standard terminology but not totally standard terminology.

881
00:49:32,865 --> 00:49:36,060
The literature I'm gonna call this VAD.

882
00:49:36,060 --> 00:49:38,520
For- Voice Activity Detection.

883
00:49:38,520 --> 00:49:41,860
[NOISE] Right.

884
00:49:41,860 --> 00:49:44,470
Um, it turns out that voice activity detection,

885
00:49:44,470 --> 00:49:46,150
there's a standard component is in

886
00:49:46,150 --> 00:49:51,430
many different speech recognition systems if you are using a cellphone for example,

887
00:49:51,430 --> 00:49:55,540
VAD is a component that tries to figure out if anyone's even talking because if they think

888
00:49:55,540 --> 00:49:59,965
no one is talking then there's no need to encode the audio and try to transmit the audio,

889
00:49:59,965 --> 00:50:01,810
right? Aarti, could you?

890
00:50:01,810 --> 00:50:02,590
Okay.

891
00:50:02,590 --> 00:50:07,780
Yeah. [LAUGHTER] Yeah. Um, and so,

892
00:50:07,780 --> 00:50:12,550
uh, so the next question I want to ask you and,

893
00:50:12,550 --> 00:50:16,705
and I- I- I thought this is timely because, um, uh,

894
00:50:16,705 --> 00:50:23,275
well there's a couple options, right?

895
00:50:23,275 --> 00:50:28,090
Option one is to build a non-machine learning-based VAD system,

896
00:50:28,090 --> 00:50:31,285
Voice Activity Detection system which is just, you know,

897
00:50:31,285 --> 00:50:37,135
see if the volume

898
00:50:37,135 --> 00:50:41,380
of the audio your smart speaker is recording is greater than epsilon.

899
00:50:41,380 --> 00:50:44,275
So, the silence just forget it.

900
00:50:44,275 --> 00:50:52,690
And option two is train a small neural network, um,

901
00:50:52,690 --> 00:50:54,280
to recognize on, on,

902
00:50:54,280 --> 00:51:01,480
on human speech, right?

903
00:51:01,480 --> 00:51:07,255
And so, uh, my next question to you is,

904
00:51:07,255 --> 00:51:08,965
um, if you're working on this project,

905
00:51:08,965 --> 00:51:12,355
would you pick option one or would you pick option two?

906
00:51:12,355 --> 00:51:14,740
Right? As you, as you,

907
00:51:14,740 --> 00:51:17,530
as you move toward- oh sorry and I think,

908
00:51:17,530 --> 00:51:19,405
um, a small neural network.

909
00:51:19,405 --> 00:51:22,150
So, a small neural network or in some cases,

910
00:51:22,150 --> 00:51:24,310
I've seen people use a small support vector machine

911
00:51:24,310 --> 00:51:26,035
as well for those who don't know what that is.

912
00:51:26,035 --> 00:51:28,690
A small model can be run with a low computational budget.

913
00:51:28,690 --> 00:51:31,540
There's a much simpler problem to detect if someone is talking than to

914
00:51:31,540 --> 00:51:34,570
recognize a word they said so you can actually do this, you know,

915
00:51:34,570 --> 00:51:38,590
but this with reasonable accuracy with a small neural network but if you actually work on

916
00:51:38,590 --> 00:51:43,405
this project for CS 230 which would you try first?

917
00:51:43,405 --> 00:51:45,895
So, could we come to the next question?

918
00:51:45,895 --> 00:51:46,420
Yes.

919
00:51:46,420 --> 00:51:46,870
Okay.

920
00:51:46,870 --> 00:51:48,085
I cant figure out how to do that.

921
00:51:48,085 --> 00:51:48,417
Oh oh sure.

922
00:51:48,417 --> 00:51:48,550
Okay.

923
00:51:48,550 --> 00:51:50,800
Yeah, yeah, yeah, you can let them

924
00:51:50,800 --> 00:51:53,560
start answering I guess and then while you figure out the projection.

925
00:51:53,560 --> 00:51:58,570
Cool.

926
00:51:58,570 --> 00:52:01,370
I will just keep unlocking it periodically.

927
00:52:02,700 --> 00:52:05,425
Are people able to vote?

928
00:52:05,425 --> 00:52:08,180
No, there are no votes yet.

929
00:52:13,110 --> 00:52:20,200
Well, I guess you write so much code,

930
00:52:20,200 --> 00:52:29,320
you have a shortcut to go so you're coding environment on your laptop. Great. [LAUGHTER].

931
00:52:29,320 --> 00:52:30,800
Yeah. That way?

932
00:52:31,230 --> 00:52:34,870
All right cool. Great thank you.

933
00:52:34,870 --> 00:52:48,820
[NOISE]

934
00:52:48,820 --> 00:52:52,990
Oh wow! Great. Right. You're answering quickly.

935
00:52:52,990 --> 00:52:56,680
Another like 20 seconds if that's enough time to give the answers.

936
00:52:56,680 --> 00:53:21,630
[NOISE]

937
00:53:21,630 --> 00:53:22,350
All right cool.

938
00:53:22,350 --> 00:53:30,475
Um, that's fascinating.

939
00:53:30,475 --> 00:53:32,665
There's a lot of disagreement in this class.

940
00:53:32,665 --> 00:53:35,490
Um, people must say why,

941
00:53:35,490 --> 00:53:37,020
why would you choose option one,

942
00:53:37,020 --> 00:53:38,355
why would you option two?

943
00:53:38,355 --> 00:53:42,570
And then I- I- I- I- I have a very strong point of view on what I would do, right?

944
00:53:42,570 --> 00:53:44,490
Um, but, but I'm curious why,

945
00:53:44,490 --> 00:53:47,490
uh, why option one and why option two. Go ahead.

946
00:53:47,490 --> 00:53:53,220
Option one is easy to debug in the environment.

947
00:53:53,220 --> 00:53:58,200
Easy to debug. Anything else? Either option one or option two?

948
00:53:58,200 --> 00:54:00,135
Option one is simple.

949
00:54:00,135 --> 00:54:03,375
Option one is simple. Anything else?

950
00:54:03,375 --> 00:54:05,970
Option two is not an environment.

951
00:54:05,970 --> 00:54:08,310
Option two is not the environment. [LAUGHTER].

952
00:54:08,310 --> 00:54:12,480
I was thinking the option one, right?

953
00:54:12,480 --> 00:54:15,960
If you've a dog in your house and he barks and it can activate.

954
00:54:15,960 --> 00:54:17,730
So, when you have option two,

955
00:54:17,730 --> 00:54:24,775
you can probably kind of already like simplify the problem but it does not,

956
00:54:24,775 --> 00:54:26,095
is another way to I mean,

957
00:54:26,095 --> 00:54:28,630
activates the machine but doesn't by itself.

958
00:54:28,630 --> 00:54:30,595
[NOISE] That's why if it's talking to.

959
00:54:30,595 --> 00:54:32,095
Yeah, if the dog barking.

960
00:54:32,095 --> 00:54:33,370
Option two, it would be much better.

961
00:54:33,370 --> 00:54:36,450
Yeah, yeah, someth- something kinda goes noise.

962
00:54:36,450 --> 00:54:40,150
Cool. All right. And just two of you and in each-.

963
00:54:40,150 --> 00:54:46,180
Option two, they're making noise from people like whispering?

964
00:54:46,180 --> 00:54:49,771
Like, what if someone is whispering?

965
00:54:49,771 --> 00:54:50,440
Huh?

966
00:54:50,440 --> 00:54:52,030
What if someone is whispering?

967
00:54:52,030 --> 00:54:53,770
What if someone's whispering?

968
00:54:53,770 --> 00:55:06,280
[inaudible].

969
00:55:06,280 --> 00:55:08,090
Yeah, yeah, go. Yeah, go ahead, have you.

970
00:55:08,090 --> 00:55:10,090
[inaudible]

971
00:55:10,090 --> 00:55:13,190
I think it will pick up the background noise.

972
00:55:13,320 --> 00:55:17,065
Yeah, cool, yeah. And in a noisy place like, you know,

973
00:55:17,065 --> 00:55:18,475
I have a friend who's, uh,

974
00:55:18,475 --> 00:55:20,740
lives actually listening to the train station.

975
00:55:20,740 --> 00:55:21,790
So, right, so.

976
00:55:21,790 --> 00:55:23,830
option one will cover a lot of things [NOISE],

977
00:55:23,830 --> 00:55:24,880
which is possible. Yeah.

978
00:55:24,880 --> 00:55:27,580
Whichever option you take has to be running constantly.

979
00:55:27,580 --> 00:55:29,350
So, you want something that is very cheap,

980
00:55:29,350 --> 00:55:34,980
so it seems like option one is better than [inaudible].

981
00:55:34,980 --> 00:55:38,215
Yeah, whether we pick has to be constan- constantly somehow to be cheap,

982
00:55:38,215 --> 00:55:39,745
low power, low conflict.

983
00:55:39,745 --> 00:55:42,250
So, le- let me show you some of the pros and cons.

984
00:55:42,250 --> 00:55:45,370
Um, uh, so, um,

985
00:55:45,370 --> 00:55:47,485
uh, I think, yeah,

986
00:55:47,485 --> 00:55:50,155
there are pros and cons in option one and option two was why there's so,

987
00:55:50,155 --> 00:55:53,290
so, so many votes were both options.

988
00:55:53,290 --> 00:55:55,615
I perceived we'll choose option one.

989
00:55:55,615 --> 00:55:57,115
Um, but, but let me just,

990
00:55:57,115 --> 00:55:59,065
let's just discuss the pros and cons, right?

991
00:55:59,065 --> 00:56:00,885
I think that's, um, uh,

992
00:56:00,885 --> 00:56:04,525
option one, um, forces just a few lines of codes.

993
00:56:04,525 --> 00:56:06,865
Is, is yes, maybe options two isn't that complicated,

994
00:56:06,865 --> 00:56:09,345
but option one is even simpler.

995
00:56:09,345 --> 00:56:12,300
And I think that, um, uh,

996
00:56:12,300 --> 00:56:14,190
actually maybe I would say if I hadn't worked on

997
00:56:14,190 --> 00:56:16,455
this problem before I will choose option one.

998
00:56:16,455 --> 00:56:18,240
Uh, but since I have experience in

999
00:56:18,240 --> 00:56:20,805
speech recognition eventually I know you need option two.

1000
00:56:20,805 --> 00:56:23,740
But that's because I, I because I've worked on this problem before.

1001
00:56:23,740 --> 00:56:26,335
But if it's your first time working on the speech activation problem,

1002
00:56:26,335 --> 00:56:29,290
I would encourage you on average to try

1003
00:56:29,290 --> 00:56:33,250
to really simple quick and direct solutions and go ahead and,

1004
00:56:33,250 --> 00:56:36,595
um, so let's see how long would it take to implement this.

1005
00:56:36,595 --> 00:56:38,530
Right? I would say like 10 minutes,

1006
00:56:38,530 --> 00:56:41,245
five minutes, I don't know, right?

1007
00:56:41,245 --> 00:56:43,300
How long would it take to implement that?

1008
00:56:43,300 --> 00:56:44,965
i don't know. Like what?

1009
00:56:44,965 --> 00:56:46,195
Four hours? One day?

1010
00:56:46,195 --> 00:56:48,235
I, I, I don't really know actually.

1011
00:56:48,235 --> 00:56:50,320
Right. Um, le- let me just write one day,

1012
00:56:50,320 --> 00:56:51,820
I'm, I'm not quite sure.

1013
00:56:51,820 --> 00:56:54,100
Right, but if, um,

1014
00:56:54,100 --> 00:56:59,005
option one can be implemented in 10 minutes then I would encourage you to do that.

1015
00:56:59,005 --> 00:57:04,465
And go ahead and put the smart speaker in your home or in your potential users homes.

1016
00:57:04,465 --> 00:57:08,230
And only when you find out that the dog barking

1017
00:57:08,230 --> 00:57:11,920
is a problem or the train on the railway station or whatever is a problem,

1018
00:57:11,920 --> 00:57:15,090
then go back and invest more in fixing it, right?

1019
00:57:15,090 --> 00:57:16,470
And, in fact, um,

1020
00:57:16,470 --> 00:57:20,790
It's true that maybe it's annoying if the dog barking keeps on waking up the system.

1021
00:57:20,790 --> 00:57:24,570
But maybe that's okay because if the large neural network then screens out

1022
00:57:24,570 --> 00:57:28,425
all the dog barking then the overall performance systems actually just fine.

1023
00:57:28,425 --> 00:57:30,120
And, uh, and, and,

1024
00:57:30,120 --> 00:57:32,805
and you now have a much simpler system.

1025
00:57:32,805 --> 00:57:34,710
Right? But, uh, but, but it,

1026
00:57:34,710 --> 00:57:37,480
it turns out that, um, the reason, uh,

1027
00:57:37,480 --> 00:57:39,460
you might need to go to option two eventually is

1028
00:57:39,460 --> 00:57:42,475
because there are some homes in noisy environments.

1029
00:57:42,475 --> 00:57:44,650
Uh, uh, you know, there's constant background noise,

1030
00:57:44,650 --> 00:57:48,430
and so that will keep the large neural network running a little bit too frequently,

1031
00:57:48,430 --> 00:57:51,220
so, so if you have a large engineering budget,

1032
00:57:51,220 --> 00:57:53,020
you know, so, so, some of the smart speaker teams

1033
00:57:53,020 --> 00:57:54,835
are over hundreds of engineers that are working on it.

1034
00:57:54,835 --> 00:57:56,575
So, if you have hundreds of engineers work on it,

1035
00:57:56,575 --> 00:57:59,995
totally option two will perform better.

1036
00:57:59,995 --> 00:58:02,080
But if your strap a startup team,

1037
00:58:02,080 --> 00:58:06,700
a scrappy startup team with few of you working on a class project, you know,

1038
00:58:06,700 --> 00:58:11,125
the evidence that you need that level of complexity is not that high,

1039
00:58:11,125 --> 00:58:13,570
and I would really do that first and,

1040
00:58:13,570 --> 00:58:17,320
and you start to gather evidence that you really should make the investment to build

1041
00:58:17,320 --> 00:58:21,775
more complex system before actually making the investments of days or,

1042
00:58:21,775 --> 00:58:24,895
e- er, and eventually I think this is one day to build your first prototype,

1043
00:58:24,895 --> 00:58:26,200
right, and then eventually you'll be,

1044
00:58:26,200 --> 00:58:27,880
you'll be more complicated.

1045
00:58:27,880 --> 00:58:31,525
Um, it turns out that, um,

1046
00:58:31,525 --> 00:58:34,510
the other reason [NOISE] ,

1047
00:58:34,510 --> 00:58:39,655
um, the other huge advantage of the simple method is the following.

1048
00:58:39,655 --> 00:58:44,020
Um, and this is one of the frankly,

1049
00:58:44,020 --> 00:58:46,930
this is one of the, this is actually one of the big problems and

1050
00:58:46,930 --> 00:58:50,095
big weaknesses of Machine Learning algorithms in deep learning algorithms,

1051
00:58:50,095 --> 00:58:52,330
which is what happens is, uh,

1052
00:58:52,330 --> 00:58:55,120
um, when you build a system and you ship,

1053
00:58:55,120 --> 00:58:57,955
ship a product, the data will change, right,

1054
00:58:57,955 --> 00:59:00,925
and so, um, I'm gonna simplify the example a little bit.

1055
00:59:00,925 --> 00:59:03,745
But, you know, I, I know Stanford is very cosmopolitan,

1056
00:59:03,745 --> 00:59:05,440
this Palo Alto is very cosmopolitan.

1057
00:59:05,440 --> 00:59:07,120
See, you collect data in this region,

1058
00:59:07,120 --> 00:59:09,115
you get accents from people all over the world,

1059
00:59:09,115 --> 00:59:12,120
right, because, because that's Stanford or that's Palo Alto.

1060
00:59:12,120 --> 00:59:15,045
But, but just to simplify the example a little bit, [NOISE] um,

1061
00:59:15,045 --> 00:59:21,730
let's say that you train [NOISE] on, uh, US accents,

1062
00:59:21,730 --> 00:59:25,000
right, uh, but you know,

1063
00:59:25,000 --> 00:59:26,410
for some reason, uh,

1064
00:59:26,410 --> 00:59:28,120
uh, when you ship a product,

1065
00:59:28,120 --> 00:59:32,350
maybe it sells really well in the UK and you start getting data

1066
00:59:32,350 --> 00:59:40,825
[NOISE] with a UK or with British accents.

1067
00:59:40,825 --> 00:59:45,280
Right? So, one of the biggest problems

1068
00:59:45,280 --> 00:59:49,435
you face in practical deployment of Machine Learning systems is that,

1069
00:59:49,435 --> 00:59:53,830
the data you train on is not gonna be the data you need to perform well on.

1070
00:59:53,830 --> 00:59:58,300
Um, and, and I'm gonna share with you some practical ideas for how to solve this,

1071
00:59:58,300 --> 01:00:00,969
but this is one of those practical realities

1072
01:00:00,969 --> 01:00:03,055
and practical weaknesses of Machine Learning,

1073
01:00:03,055 --> 01:00:06,640
That is actually not talked about much in academia, uh,

1074
01:00:06,640 --> 01:00:10,510
uh because it turns out that the data sets we have in academia are

1075
01:00:10,510 --> 01:00:14,460
not set up well for researchers to study and publish papers on this.

1076
01:00:14,460 --> 01:00:16,830
I think we can start new Machine Learning benchmarks in the future.

1077
01:00:16,830 --> 01:00:19,020
But there's one of those problems that is actually kind

1078
01:00:19,020 --> 01:00:21,120
of under appreciated in academic literature.

1079
01:00:21,120 --> 01:00:24,270
Uh, but that [NOISE] is a problem facing many,

1080
01:00:24,270 --> 01:00:27,435
many practical deployments of Machine Learning algorithms.

1081
01:00:27,435 --> 01:00:31,015
Um, and, uh, and so,

1082
01:00:31,015 --> 01:00:36,370
more generally, the problem is one of data changing, right, and, uh,

1083
01:00:36,370 --> 01:00:44,125
you might have new classes of users with new accents or you might train a lot on,

1084
01:00:44,125 --> 01:00:46,420
uh, the, maybe you get data from

1085
01:00:46,420 --> 01:00:50,575
even Stanford users and maybe Stanford is not too noisy or Stanford has a certain,

1086
01:00:50,575 --> 01:00:51,730
you know, types of characteristics.

1087
01:00:51,730 --> 01:00:55,450
When you ship it to another city or another country that's much more noisy,

1088
01:00:55,450 --> 01:00:57,490
uh, you know, different background noise.

1089
01:00:57,490 --> 01:01:04,375
[NOISE] Right? Or, uh,

1090
01:01:04,375 --> 01:01:09,355
you start manufacturing the smart speaker and to lower the costs of the speaker,

1091
01:01:09,355 --> 01:01:10,525
they swap it out,

1092
01:01:10,525 --> 01:01:14,950
they swap out the high-end microphone that you use from your laptop to collect the data,

1093
01:01:14,950 --> 01:01:18,985
for a lower-end microphone, [NOISE] right?

1094
01:01:18,985 --> 01:01:20,425
It's very common thing done in,

1095
01:01:20,425 --> 01:01:21,970
you know, well, done in manufacturing, right?

1096
01:01:21,970 --> 01:01:24,835
If you could use a cheaper microphone why not, right, and,

1097
01:01:24,835 --> 01:01:26,110
and often to human ears,

1098
01:01:26,110 --> 01:01:28,915
The sound sounds just fine on a cheaper microphone,

1099
01:01:28,915 --> 01:01:32,335
but if you train your learning algorithm using your,

1100
01:01:32,335 --> 01:01:33,685
you know, I guess yeah, well,

1101
01:01:33,685 --> 01:01:36,220
I use a Mac, but a Mac has a pretty decent microphones.

1102
01:01:36,220 --> 01:01:38,320
If you train the data using all you collect from a Mac

1103
01:01:38,320 --> 01:01:40,480
and then eventually has a different microphone,

1104
01:01:40,480 --> 01:01:42,760
it may not generalize well.

1105
01:01:42,760 --> 01:01:46,510
So, one of the challenges of, um,

1106
01:01:46,510 --> 01:01:50,830
Machine Learning is that you often develop a system on one data set,

1107
01:01:50,830 --> 01:01:52,390
and then when you ship a product,

1108
01:01:52,390 --> 01:01:54,970
something about the world changes, uh, and, and,

1109
01:01:54,970 --> 01:01:56,980
and your system needs to perform on

1110
01:01:56,980 --> 01:02:01,090
a very different type [NOISE] of data than what you had trained on.

1111
01:02:01,090 --> 01:02:11,260
Um, and so, [NOISE], Um, and so,

1112
01:02:11,260 --> 01:02:16,330
what will happen is after you deploy the model, uh,

1113
01:02:16,330 --> 01:02:20,560
the world may change and you often end up going back to get more data,

1114
01:02:20,560 --> 01:02:22,720
redesign the model right and,

1115
01:02:22,720 --> 01:02:23,920
and, and I guess, er, and this is,

1116
01:02:23,920 --> 01:02:27,160
this is, uh, uh, the maintenance of the Machine Learning model.

1117
01:02:27,160 --> 01:02:29,230
Uh, I wanna give some other examples.

1118
01:02:29,230 --> 01:02:32,635
A web search, right,

1119
01:02:32,635 --> 01:02:34,030
uh, this happens all the time,

1120
01:02:34,030 --> 01:02:36,190
at multiple web search engine which is, uh,

1121
01:02:36,190 --> 01:02:38,890
you train a neural network or you train a system to,

1122
01:02:38,890 --> 01:02:41,215
to give relevant web search results.

1123
01:02:41,215 --> 01:02:43,120
But then something about the world changes.

1124
01:02:43,120 --> 01:02:45,220
You know, for example there's a major political event,

1125
01:02:45,220 --> 01:02:48,490
some new person is elected president of some foreign country

1126
01:02:48,490 --> 01:02:51,820
or there's a major scandal or just the Internet changes,

1127
01:02:51,820 --> 01:02:53,935
right, or, or there's a, a, a, actually what,

1128
01:02:53,935 --> 01:02:56,770
what happens in China is that new words getting invented all the time.

1129
01:02:56,770 --> 01:02:58,930
Uh, uh, in, in, in Chin- the Chin- uh,

1130
01:02:58,930 --> 01:03:00,670
says that, by of what they Google and Baidu,

1131
01:03:00,670 --> 01:03:04,090
but the Chinese language is more fluid than the English language,

1132
01:03:04,090 --> 01:03:06,055
and so new worst get invented all the time.

1133
01:03:06,055 --> 01:03:07,930
And so, the language changes,

1134
01:03:07,930 --> 01:03:12,730
and so whether we are trained just isn't working as long as it used to, right.

1135
01:03:12,730 --> 01:03:15,670
Um, or, or, or maybe a different company,

1136
01:03:15,670 --> 01:03:17,695
suddenly shuts off, you know,

1137
01:03:17,695 --> 01:03:21,475
their entire website to your search index because they don't want you, uh,

1138
01:03:21,475 --> 01:03:23,080
indexing their website and so it's like

1139
01:03:23,080 --> 01:03:26,705
the Internet changes and what have you done doesn't work anymore.

1140
01:03:26,705 --> 01:03:31,550
Um, or, um, uh, self-driving.

1141
01:03:31,550 --> 01:03:35,865
Okay. [NOISE]. Uh, it turns out that you build a self-driving car in California,

1142
01:03:35,865 --> 01:03:40,620
and then you try to deploy these vehicles in Texas, um, you know,

1143
01:03:40,620 --> 01:03:42,670
it turns out traffic lights and Texas look

1144
01:03:42,670 --> 01:03:45,220
very different than traffic lights in, in, in California.

1145
01:03:45,220 --> 01:03:48,985
So, a model trained on California, Texas on,

1146
01:03:48,985 --> 01:03:51,880
so a neural network trained to recognize, uh,

1147
01:03:51,880 --> 01:03:56,005
California traffic lights actually doesn't work very well on Texas traffic lights.

1148
01:03:56,005 --> 01:03:58,540
Right? Uh, I'm trying to remember which way around to this,

1149
01:03:58,540 --> 01:04:00,670
but I think California and Texas have

1150
01:04:00,670 --> 01:04:04,705
a different distribution of horizontal versus vertical traffic lights for example,

1151
01:04:04,705 --> 01:04:06,655
there's actually, as humans don't notice as you go,

1152
01:04:06,655 --> 01:04:07,840
oh yeah, red, yellow, green,

1153
01:04:07,840 --> 01:04:09,730
but the learning algorithm doesn't actually generalize

1154
01:04:09,730 --> 01:04:11,770
that well if you go to a different location.

1155
01:04:11,770 --> 01:04:14,080
You've go to a foreign country, again, traffic lights,

1156
01:04:14,080 --> 01:04:17,365
signage, the lane markings all change, um.

1157
01:04:17,365 --> 01:04:19,585
Or I guess, well,

1158
01:04:19,585 --> 01:04:22,270
one example I was working on earlier this week, right?

1159
01:04:22,270 --> 01:04:24,910
Uh, manufacturing, right, landing AI,

1160
01:04:24,910 --> 01:04:29,020
working on inspection of parts in factories, um,

1161
01:04:29,020 --> 01:04:33,085
and so if you are doing visual inspection [NOISE] in the factory,

1162
01:04:33,085 --> 01:04:36,280
and the factory starts making a new component,

1163
01:04:36,280 --> 01:04:38,290
you know, they were making this model of cell phone,

1164
01:04:38,290 --> 01:04:40,570
but cell phones turn over quickly, and so,

1165
01:04:40,570 --> 01:04:43,960
but in a few months later they're making a different type of cell phone or something

1166
01:04:43,960 --> 01:04:45,700
weird happens in the manufacturing process or

1167
01:04:45,700 --> 01:04:48,010
the lighting changes and new type of defect.

1168
01:04:48,010 --> 01:04:50,290
So the world changes, right?

1169
01:04:50,290 --> 01:04:55,420
And, um, so, oh, she got locked again?

1170
01:04:55,420 --> 01:05:00,400
[NOISE] What I'd like to do is, um,

1171
01:05:00,400 --> 01:05:05,530
actually revisit the previous question in light of this,

1172
01:05:05,530 --> 01:05:09,640
uh, the world changes, phenomenon, right?

1173
01:05:09,640 --> 01:05:11,110
[NOISE] Which is, let's say you've collected a lot of

1174
01:05:11,110 --> 01:05:13,570
data with American accented speakers.

1175
01:05:13,570 --> 01:05:16,225
Um, and then, you know, we'll ship the product to the UK.

1176
01:05:16,225 --> 01:05:19,310
And then, um,

1177
01:05:20,570 --> 01:05:25,185
and then for some reason you find that you have all these British accent speakers,

1178
01:05:25,185 --> 01:05:27,765
right, trying to use your smart speaker.

1179
01:05:27,765 --> 01:05:29,730
So, between these two algorithms,

1180
01:05:29,730 --> 01:05:30,900
the non machine-learning approach,

1181
01:05:30,900 --> 01:05:33,405
which is a set the threshold versus trained in neural network.

1182
01:05:33,405 --> 01:05:37,740
Which system do you think will be more robust for VAD, voice activity detection?

1183
01:05:37,740 --> 01:05:56,470
[NOISE]

1184
01:05:56,470 --> 01:05:57,895
All right, let's take like another,

1185
01:05:57,895 --> 01:05:59,290
I don't know, 40 seconds?

1186
01:05:59,290 --> 01:06:37,030
[NOISE]

1187
01:06:37,030 --> 01:06:43,630
All right. Yeah. Interesting. Do people want to comment?

1188
01:06:43,630 --> 01:06:46,810
Well, more, more, more people voted for a non-ML.

1189
01:06:46,810 --> 01:06:50,530
Does  someone want to explain why. Yeah. Go ahead.

1190
01:06:50,530 --> 01:07:03,730
[inaudible]

1191
01:07:03,730 --> 01:07:03,910
Yeah.

1192
01:07:03,910 --> 01:07:13,900
You're right. So we say,

1193
01:07:13,900 --> 01:07:16,615
for the VAD voice-activated section, uh,

1194
01:07:16,615 --> 01:07:18,370
if you just measure the volume,

1195
01:07:18,370 --> 01:07:20,020
then it doesn't really depend on,

1196
01:07:20,020 --> 01:07:21,490
on the absolute, right?

1197
01:07:21,490 --> 01:07:23,530
So, non ML might be more robust.

1198
01:07:23,530 --> 01:07:29,290
Anyone else? [NOISE]. All right.

1199
01:07:29,290 --> 01:07:31,705
So, again I'm going to show you about.

1200
01:07:31,705 --> 01:07:33,145
So, it turns out that, um,

1201
01:07:33,145 --> 01:07:35,920
if you train a small neural network,

1202
01:07:35,920 --> 01:07:38,275
uh, to, um, uh, you know,

1203
01:07:38,275 --> 01:07:40,135
American accented speech, uh,

1204
01:07:40,135 --> 01:07:41,905
there's a bigger chance,

1205
01:07:41,905 --> 01:07:43,480
that your neural network,

1206
01:07:43,480 --> 01:07:45,355
because it's so clever, right?

1207
01:07:45,355 --> 01:07:47,590
They'll learn to recognize American speech,

1208
01:07:47,590 --> 01:07:53,560
[NOISE] and have a harder time generalizing to British accented speech. Do I make sense?

1209
01:07:53,560 --> 01:07:57,640
And so, one of the things that I've seen a lot of teams,

1210
01:07:57,640 --> 01:07:59,170
uh, where-where's, so, so,

1211
01:07:59,170 --> 01:08:02,680
one way that non ML thing could fail to generalize,

1212
01:08:02,680 --> 01:08:04,915
would be that British speakers are systematically,

1213
01:08:04,915 --> 01:08:07,540
you know, louder or softer than American speakers, right?

1214
01:08:07,540 --> 01:08:09,490
So, you know, I know. I don't know if

1215
01:08:09,490 --> 01:08:12,310
Americans stereo typically are louder or less loud than British,

1216
01:08:12,310 --> 01:08:15,325
but, but, you know, but if, but if American and British speakers one,

1217
01:08:15,325 --> 01:08:18,609
one country just has louder voices as softer voices,

1218
01:08:18,609 --> 01:08:21,969
there maybe, the threshold you set won't generalize well,

1219
01:08:21,970 --> 01:08:23,319
but that seems unlikely.

1220
01:08:23,319 --> 01:08:25,254
I, I don't see that being realistically.

1221
01:08:25,255 --> 01:08:30,189
But, um, but if you train your neural network a lot, parameters, then, uh,

1222
01:08:30,189 --> 01:08:32,919
it's more likely that the neural network will pick up

1223
01:08:32,920 --> 01:08:35,890
on some idiosyncrasy of American accents,

1224
01:08:35,890 --> 01:08:38,890
to decide the [NOISE] salaries even speaking, um,

1225
01:08:38,890 --> 01:08:43,944
and thus maybe less robust in generalizing into British accented speech, right?

1226
01:08:43,944 --> 01:08:45,279
And, another way to think about this,

1227
01:08:45,279 --> 01:08:47,574
is if you imagine to take it even further example,

1228
01:08:47,575 --> 01:08:50,109
imagine that, um, you're using VAD for

1229
01:08:50,109 --> 01:08:53,349
a totally different language than, than English, right?

1230
01:08:53,350 --> 01:08:55,975
Where, um, take a different language, you know,

1231
01:08:55,975 --> 01:09:00,564
Chinese or Hindi or Spanish or something where the sounds are really different.

1232
01:09:00,564 --> 01:09:04,164
If you train a VAD system to detect, you know, English,

1233
01:09:04,165 --> 01:09:08,920
it may not allow work for detecting Spanish or Chinese or French or,

1234
01:09:08,920 --> 01:09:11,200
or some other language.

1235
01:09:11,200 --> 01:09:13,885
Um. And so, do you think of British accents as uh,

1236
01:09:13,885 --> 01:09:15,295
as somewhere on the spectrum.

1237
01:09:15,295 --> 01:09:16,810
Not a foreign language by any means,

1238
01:09:16,810 --> 01:09:18,234
but just more different,

1239
01:09:18,234 --> 01:09:19,629
than, I think the,

1240
01:09:19,630 --> 01:09:21,670
um, non ML system is, is,

1241
01:09:21,670 --> 01:09:24,189
is more likely to be robust, right?

1242
01:09:24,189 --> 01:09:26,709
And so, one of the lessons that too many, that,

1243
01:09:26,710 --> 01:09:29,950
that a lot of machine learning teams learn the hard way is uh,

1244
01:09:29,950 --> 01:09:33,115
um, if you don't need to use a learning algorithm for something,

1245
01:09:33,115 --> 01:09:35,319
if you can hand code a simple rule, like,

1246
01:09:35,319 --> 01:09:38,319
if volume greater than 0.01,

1247
01:09:38,319 --> 01:09:42,144
do this or that, uh, those rules are can more robust.

1248
01:09:42,145 --> 01:09:44,590
Um, and, the, one of the reasons we

1249
01:09:44,590 --> 01:09:47,215
use learning algorithms is when we can't hand code something, like,

1250
01:09:47,215 --> 01:09:49,540
I don't know how to hand code something to detect a cat,

1251
01:09:49,540 --> 01:09:51,010
or detect the car on the road,

1252
01:09:51,010 --> 01:09:52,479
or detect the person.

1253
01:09:52,479 --> 01:09:54,264
So, use learning algorithms with those.

1254
01:09:54,265 --> 01:09:56,050
But if there is such an encoded rule,

1255
01:09:56,050 --> 01:09:58,075
that actually does pretty well,

1256
01:09:58,075 --> 01:10:04,525
you find that it is more robust to shift into data and will often generalize better.

1257
01:10:04,525 --> 01:10:07,015
And uh, if any of you take a, uh, uh,

1258
01:10:07,015 --> 01:10:08,770
we talk a bit this,

1259
01:10:08,770 --> 01:10:10,840
about this little bit in CS 229,

1260
01:10:10,840 --> 01:10:13,495
I think CS 229 talks about this as well,

1261
01:10:13,495 --> 01:10:17,305
but this particular observation is backed up by very rigorous learning theory.

1262
01:10:17,305 --> 01:10:18,490
And the learning theory,

1263
01:10:18,490 --> 01:10:21,565
is basically that the fewer parameters you have, uh,

1264
01:10:21,565 --> 01:10:23,530
if you still do well on your training set.

1265
01:10:23,530 --> 01:10:25,555
If you can have model with very few parameters,

1266
01:10:25,555 --> 01:10:26,980
that does well on your training set,

1267
01:10:26,980 --> 01:10:28,510
you would generalize better, right.

1268
01:10:28,510 --> 01:10:32,395
So, there's this very rigorous machine learning theory that basically says that,

1269
01:10:32,395 --> 01:10:34,855
and in the case of the non machine-learning approach there's

1270
01:10:34,855 --> 01:10:37,855
maybe one parameter which is what's the threshold for epsilon.

1271
01:10:37,855 --> 01:10:40,030
And that's worked well enough for your training set,

1272
01:10:40,030 --> 01:10:43,480
then you are severe generalizing even when the data changes is,

1273
01:10:43,480 --> 01:10:45,970
um, much higher, right?

1274
01:10:45,970 --> 01:10:48,810
Um.

1275
01:10:48,810 --> 01:10:53,605
Now, the last question,

1276
01:10:53,605 --> 01:10:58,990
um, I want to pose for discussion today is, um,

1277
01:10:58,990 --> 01:11:01,690
when when discussing deployments, uh, oh, and,

1278
01:11:01,690 --> 01:11:03,205
and so, one of the lessons of deployment is,

1279
01:11:03,205 --> 01:11:04,720
that's just the way the world works.

1280
01:11:04,720 --> 01:11:06,460
Yeah. Pretty machinery system deployed,

1281
01:11:06,460 --> 01:11:09,160
the world will usually change and you often end up collecting

1282
01:11:09,160 --> 01:11:12,280
data and having integrated and maybe improve the model, right?

1283
01:11:12,280 --> 01:11:14,635
And you have fixed a model for British speakers around you.

1284
01:11:14,635 --> 01:11:18,505
Um. So, we talked about edge deployments,

1285
01:11:18,505 --> 01:11:21,610
as well as cloud deployments, right?

1286
01:11:21,610 --> 01:11:26,589
And so, um, ignoring issues of user privacy and latency,

1287
01:11:26,589 --> 01:11:27,700
which are super important,

1288
01:11:27,700 --> 01:11:29,530
but for purposes of question let's, let's,

1289
01:11:29,530 --> 01:11:33,145
let's put aside issues of user privacy and network latency.

1290
01:11:33,145 --> 01:11:35,305
Um, if you need to maintain the model,

1291
01:11:35,305 --> 01:11:37,855
so it means there's means of updating the model, right?

1292
01:11:37,855 --> 01:11:39,310
Even as the world changes.

1293
01:11:39,310 --> 01:11:43,000
[NOISE]. Um, oh sorry I miss, I miss typed.

1294
01:11:43,000 --> 01:11:47,200
It should read, does a cloud or edge deployment make maintenance easier, not of, right?

1295
01:11:47,200 --> 01:11:51,610
Uh, once you, once you just enter a one word answer, and, and why?

1296
01:11:51,610 --> 01:11:55,930
[NOISE] And so, maintenance is when the world changes, something changes.

1297
01:11:55,930 --> 01:11:57,850
So you need to update the learning model to take

1298
01:11:57,850 --> 01:12:00,040
advant- take care of this British accent.

1299
01:12:00,040 --> 01:12:03,800
So, which type of deployment makes it easier?

1300
01:12:07,710 --> 01:12:11,290
Let's take like, yeah, another two minutes to enter your answers.

1301
01:12:11,290 --> 01:13:14,470
[NOISE]

1302
01:13:14,470 --> 01:13:17,570
All right. Another like 50 seconds.

1303
01:13:57,150 --> 01:14:01,000
All right. Cool. Now, see what people wrote.

1304
01:14:01,000 --> 01:14:08,170
[NOISE] Wow.

1305
01:14:08,170 --> 01:14:09,310
Cool. Great. All right.

1306
01:14:09,310 --> 01:14:11,660
Almost everyone is saying Clouds.

1307
01:14:15,570 --> 01:14:18,520
Most people are saying cloud.

1308
01:14:18,520 --> 01:14:21,160
Almost. All right.

1309
01:14:21,160 --> 01:14:23,440
Cool. Great. And, and just to summarize,

1310
01:14:23,440 --> 01:14:25,495
I think there are actually two reasons why.

1311
01:14:25,495 --> 01:14:28,750
Most people said it's easier to push updates, that's part of it.

1312
01:14:28,750 --> 01:14:30,010
I think the other part of it,

1313
01:14:30,010 --> 01:14:31,810
is that if all the data that is at the edge.

1314
01:14:31,810 --> 01:14:33,310
If all the data is processed, you know,

1315
01:14:33,310 --> 01:14:35,245
in the user's home and another constant cloud,

1316
01:14:35,245 --> 01:14:38,470
then even if you have all of these unhappy British accents it uses,

1317
01:14:38,470 --> 01:14:39,850
you may not even find out, right?

1318
01:14:39,850 --> 01:14:41,500
You're sitting in the company headquarters,

1319
01:14:41,500 --> 01:14:43,645
you have all these users and mysterious things, you know,

1320
01:14:43,645 --> 01:14:46,960
seem to be not using your device maybe because they're unsatisfied with it,

1321
01:14:46,960 --> 01:14:49,960
but if the data isn't coming into your servers in the cloud,

1322
01:14:49,960 --> 01:14:51,445
then you might not even find anything about it.

1323
01:14:51,445 --> 01:14:54,085
Now, there's serious issues about user privacy,

1324
01:14:54,085 --> 01:14:55,840
uh, uh, as well as security, right?

1325
01:14:55,840 --> 01:14:57,760
So, so, so, please if you haven't bought the product,

1326
01:14:57,760 --> 01:15:00,040
please be respectful of that, uh,

1327
01:15:00,040 --> 01:15:01,135
uh and then take, take,

1328
01:15:01,135 --> 01:15:04,660
take care of that in a very thoughtful and respectful way of users.

1329
01:15:04,660 --> 01:15:06,580
But um, [NOISE] if, uh,

1330
01:15:06,580 --> 01:15:11,050
first if, um, so this is the cloud, right?

1331
01:15:11,050 --> 01:15:15,460
If you have a lot of edge devices and all the data is processed there.

1332
01:15:15,460 --> 01:15:18,670
Um, you won't even know what your users are doing.

1333
01:15:18,670 --> 01:15:21,265
And they're happy or unhappy. You just don't know.

1334
01:15:21,265 --> 01:15:24,910
But, if some of the data in a stream to your servers in the cloud,

1335
01:15:24,910 --> 01:15:26,725
and if the user privacy with

1336
01:15:26,725 --> 01:15:31,125
really fiscious good user consent tells you for what you're doing with the data,

1337
01:15:31,125 --> 01:15:34,320
but if you take care of that in a, in a, in a, in a,

1338
01:15:34,320 --> 01:15:36,300
in a reasonable and sound way,

1339
01:15:36,300 --> 01:15:38,595
if you're able to examine some of the data,

1340
01:15:38,595 --> 01:15:42,645
then you can at least figure out that gee looks like analyzing the data,

1341
01:15:42,645 --> 01:15:44,070
there are these people at this axon,

1342
01:15:44,070 --> 01:15:45,870
there's background noise that, um,

1343
01:15:45,870 --> 01:15:51,300
uh is uh, giving it bad product experience and you can also maybe have the data,

1344
01:15:51,300 --> 01:15:53,355
so you can gather the data from the edge,

1345
01:15:53,355 --> 01:15:56,040
to feed back to your model, right?

1346
01:15:56,040 --> 01:15:59,115
So, so it let's you detect that something's gone wrong,

1347
01:15:59,115 --> 01:16:03,169
um, unless you have the data to retrain the model,

1348
01:16:03,169 --> 01:16:05,065
so solve that British accent problem,

1349
01:16:05,065 --> 01:16:08,170
we can retrain the model for more British accented speech,

1350
01:16:08,170 --> 01:16:11,125
and then finally let's you push the model back up.

1351
01:16:11,125 --> 01:16:15,130
All right. So, [NOISE] first, it let's you detect what's going on, two,

1352
01:16:15,130 --> 01:16:17,899
it gives you data for training,

1353
01:16:19,050 --> 01:16:23,140
and three, unless you more easily push the model backup.

1354
01:16:23,140 --> 01:16:27,610
Uh, push, push, push the new model to production, to deployment, okay?

1355
01:16:27,610 --> 01:16:30,075
Um, and this is also why, uh,

1356
01:16:30,075 --> 01:16:33,105
even if your computation needs to run on the edge.

1357
01:16:33,105 --> 01:16:35,310
If um, you could in a way

1358
01:16:35,310 --> 01:16:38,385
respectful of user privacy and it's transparent at the how you use data,

1359
01:16:38,385 --> 01:16:41,440
if you can get even a small sample of data,

1360
01:16:41,440 --> 01:16:44,755
or have a few volunteer users send you some data back to the cloud,

1361
01:16:44,755 --> 01:16:48,025
that will greatly increase your ability to detect there's something's gone wrong,

1362
01:16:48,025 --> 01:16:50,860
as well as maybe give you some data to retrain the model.

1363
01:16:50,860 --> 01:16:52,510
Uh, so even if you can only do,

1364
01:16:52,510 --> 01:16:54,850
so that push updates, right, this, this will,

1365
01:16:54,850 --> 01:16:56,395
this will help greatly,

1366
01:16:56,395 --> 01:16:59,110
okay? Um. All right.

1367
01:16:59,110 --> 01:17:02,965
So, finally, one last comment I think uh, one, one,

1368
01:17:02,965 --> 01:17:04,495
one last challenge is uh,

1369
01:17:04,495 --> 01:17:06,100
in a lot of machine learning systems,

1370
01:17:06,100 --> 01:17:07,630
you're not done at deployment.

1371
01:17:07,630 --> 01:17:09,895
There's a constant ongoing maintenance process.

1372
01:17:09,895 --> 01:17:13,275
And I think, one of the processes, uh, you know,

1373
01:17:13,275 --> 01:17:15,720
AI teams are getting better and as well, setting up QA,

1374
01:17:15,720 --> 01:17:17,535
to make sure that we update the model,

1375
01:17:17,535 --> 01:17:18,810
you don't break something.

1376
01:17:18,810 --> 01:17:20,580
So I think, QA and large companies,

1377
01:17:20,580 --> 01:17:22,890
quality assurance processes is kind of testers.

1378
01:17:22,890 --> 01:17:25,470
And I think the way you test machine [NOISE] learning algorithms is

1379
01:17:25,470 --> 01:17:27,960
different in the way you test traditional software,

1380
01:17:27,960 --> 01:17:29,880
because the performance of machine learning algorithms is

1381
01:17:29,880 --> 01:17:32,340
often measured in a statistical way, right?

1382
01:17:32,340 --> 01:17:34,005
So it doesn't work and it doesn't work.

1383
01:17:34,005 --> 01:17:36,000
It, it, it neither works nor doesn't work.

1384
01:17:36,000 --> 01:17:39,390
Instead it works, you know, 95% of the time or something, and so,

1385
01:17:39,390 --> 01:17:42,550
lot of companies are evolving the QA processes to have

1386
01:17:42,550 --> 01:17:45,730
this type of statistical testing to make sure that even if you change the model,

1387
01:17:45,730 --> 01:17:46,975
you do a push update,

1388
01:17:46,975 --> 01:17:48,085
it still works, you know,

1389
01:17:48,085 --> 01:17:50,890
95 or 99% of the time or something rather than so,

1390
01:17:50,890 --> 01:17:55,045
so, so putting in place new QA test processes as well.

1391
01:17:55,045 --> 01:17:57,295
Okay? All right.

1392
01:17:57,295 --> 01:17:59,380
Hope that was helpful stepping through what

1393
01:17:59,380 --> 01:18:01,870
the full arc of a machine learning project will look like.

1394
01:18:01,870 --> 01:18:05,470
Uh,will, will later this quarter or in course three as well as in later,

1395
01:18:05,470 --> 01:18:07,390
lectures are present, [NOISE] we'll keep talking about

1396
01:18:07,390 --> 01:18:10,255
machine learning strategy and how they make decisions things.

1397
01:18:10,255 --> 01:18:12,800
So, let's break for today.

